**************************************************************************
 *             __________               __   ___.
 *   Open      \______   \ ____   ____ |  | _\_ |__   _______  ___
 *   Source     |       _//  _ \_/ ___\|  |/ /| __ \ /  _ \  \/  /
 *   Jukebox    |    |   (  <_> )  \___|    < | \_\ (  <_> > <  <
 *   Firmware   |____|_  /\____/ \___  >__|_ \|___  /\____/__/\_ \
 *                     \/            \/     \/    \/            \/
 * $Id$
 *
 * Copyright (C) 2005 by Miika Pekkarinen
 *
 * This program is free software; you can redistribute it and/or
 * modify it under the terms of the GNU General Public License
 * as published by the Free Software Foundation; either version 2
 * of the License, or (at your option) any later version.
 *
 * This software is distributed on an "AS IS" basis, WITHOUT WARRANTY OF ANY
 * KIND, either express or implied.
 *
 ***************************************************************************
 *                    TagCache API
 * 
 *       ----------x---------x------------------x-----
 *                 |         |                  |              External
 * +---------------x-------+ |       TagCache   |              Libraries
 * | Modification routines | |         Core     |           
 * +-x---------x-----------+ |                  |           
 *   | (R/W)   |             |                  |           |
 *   |  +------x-------------x-+  +-------------x-----+     |
 *   |  |                      x==x Filters & clauses |     |
 *   |  | Search routines      |  +-------------------+     |
 *   |  |                      x============================x DirCache
 *   |  +-x--------------------+                            | (optional)
 *   |    | (R)                                             |
 *   |    | +-------------------------------+  +---------+  |
 *   |    | | DB Commit (sort,unique,index) |  |         |  |
 *   |    | +-x--------------------------x--+  | Control |  |
 *   |    |   | (R/W)                    | (R) | Thread  |  |
 *   |    |   | +----------------------+ |     |         |  |
 *   |    |   | | TagCache DB Builder  | |     +---------+  |
 *   |    |   | +-x-------------x------+ |                  |
 *   |    |   |   | (R)         | (W)    |                  |
 *   |    |   |   |          +--x--------x---------+        |
 *   |    |   |   |          | Temporary Commit DB |        |
 *   |    |   |   |          +---------------------+        |
 * +-x----x-------x--+                                      |
 * | TagCache RAM DB x==\(W) +-----------------+            |
 * +-----------------+   \===x                 |            |
 *   |    |   |   |      (R) |  Ram DB Loader  x============x DirCache
 * +-x----x---x---x---+   /==x                 |            | (optional)
 * | Tagcache Disk DB x==/   +-----------------+            |  
 * +------------------+                                     |
 * 
 #define LOGF_ENABLE readlink()  PATH_MAX  Tag Cache thread.  Previous path when scanning directory tree recursively.  Used when removing duplicates.  Allocated when needed.  Current location in buffer.  Buffer size (TEMPBUF_SIZE).  Buffer space left.  Tags we want to get sorted (loaded to the tempbuf).  Uniqued tags (we can use these tags with filters and conditional clauses).  String presentation of the tags defined in tagcache.h. Must be in correct order!  Status information of the tagcache.  Queue commands.  Internal tagcache command queue.  Tag database structures.  Variable-length tag entry in tag files.  Length of the data in bytes including '\0'  Corresponding entry location in index file of not unique tags  Begin of the tag data  Fixed-size tag entry in master db index.  Location of tag data or numeric tag data  Status flags  Header is the same in every file.  Header version number  Data size in bytes  Number of entries in this file  Increasing counting number  Number of commits so far  For the endianess correction *
 Note: This should be (1 + TAG_COUNT) amount of l's.
  HAVE_DIRCACHE  Header is created when loading database to ram.  Tag file content (dcfrefs if tag_filename)  Number of entries in the indices.  Master index file content  Statefile version number  Header from the master index  Old load address of hdr for relocation  HAVE_EEPROM_SETTINGS  In-RAM ramcache structure (not persisted)  allocated ramcache_header  buffer handle  ndef HAVE_TC_RAMCACHE  HAVE_TC_RAMCACHE * 
 * Full tag entries stored in a temporary file waiting 
 * for commit to the cache.  Lookup buffer for fixing messed up index while after sorting.  Used when building the temporary file.  Thread safe locking  Yeah, malloc would be really nice now :)  !__PCTOOL__  __PCTOOL__  Helper functions for the two most read/write data structure: tagfile_entry and index_entry  Check the header.  Check the header.  Success.  Trying to read again, this time with endianess correction enabled.  Sorting can lock up for quite a while, so yield occasionally  __PCTOOL__  find the ramcache entry corresponding to the file indicated by
 * filename and dc (it's corresponding dircache id).  Check if tagcache is loaded into ram.  Search references  defined (HAVE_TC_RAMCACHE) && defined (HAVE_DIRCACHE)  Note: Don't use MAX_PATH here, it's too small  APPLICATION  Not found?  HAVE_TC_RAMCACHE  We need to exclude all memory only flags & tags when writing to disk.  Only update numeric data. Writing the whole index to RAM by memcpy
     * destroys dircache pointers!
      Don't touch the dircache flag or attributes.  HAVE_TC_RAMCACHE  !__PCTOOL__  HAVE_DIRCACHE  HAVE_TC_RAMCACHE  Attempt to find tag data through store-to-load forwarding in
           command queue  A straight calculus gives:
                     autoscore = 100 * playtime / length / playcout (1)
                   Now, consider the euclidian division of playtime by length:
                     playtime = alpha * length + beta
                   With:
                     0 <= beta < length
                   Now, (1) becomes:
                     autoscore = 100 * (alpha / playcout + beta / length / playcount)
                   Both terms should be small enough to avoid any overflow
                 How many commits before the file has been added to the DB.  return filename; caller handles basename  FALLTHRU  Go through all conditional clauses.  all conditions before logical-or satisfied --
                      stop processing clauses  str points to movable data, but no locking required here,
                     * as no yield() is following  HAVE_TC_RAMCACHE  Check if entry has been deleted.  Clause failed -- try finding a logical-or clause  Found logical-or?  Check clauses after logical-or  If uniq buffer is not defined we must return true for search to work.  Return false if entry is found.  lock because below makes a pointer to movable data  idx points to movable data, don't yield or reload  Skip deleted files.  Go through all filters..  Check for conditions.  Add to the seek list if not already in uniq buffer (doesn't yield) Lets add it.  HAVE_TC_RAMCACHE  Check if entry has been deleted.  Go through all filters..  Check for conditions.  Add to the seek list if not already in uniq buffer.  Lets add it.  Always open as R/W so we can pass tcs to functions that modify data also
         * without failing.  Check if there is already a similar filter in present (filters are
         * much faster than clauses). 
          Relative fetch.  We need to retrieve flag status for dircache.  Check for end of list.  Try to fetch more.  Direct fetch.  else do it the hard way  HAVE_DIRCACHE  don't return ep->tag_data directly as it may move  was true before we copied to buf too  Increase position for the next run. This may get overwritten.  HAVE_TC_RAMCACHE  Seek stream to the correct position and continue to direct fetch. *
     Update the position for the next read (this may be overridden
     if filters or clauses are being used).
      Write it back  Find the corresponding entry in tagcache.  this macro sets id3 strings by copying to the id3v2buf  initialize with null if tag doesn't exist  defined(HAVE_TC_RAMCACHE) && defined(HAVE_DIRCACHE)  Tag length  GCC 3.4.6 for Coldfire can choose to inline this function. Not a good
 * idea, as it uses lots of stack and is called from a recursive function
 * (check_dir).
  Adding tag  Crude logging for the sim - to aid in debugging  SIMULATOR  Check for overlength file path.  Path can't be shortened.  Check if the file is supported.  Check if the file is already cached.  Be sure the entry doesn't exist.  Check if file has been modified.  TODO: Mark that the index exists (for fast reverse scan) found_idx[idx_id/8] |= idx_id%8; No changes to file.  Metadata might have been changed. Delete the entry.  Track number missing?  Numeric tags  String tags.  Write the header  And tags also... Correct order is critical  Check if the crc does not exist -> entry does not exist for sure.  Insert to CRC buffer.  Insert it to the buffer.  Generate reverse lookup entries.  Fix the lookup list.  Check the chunk alignment.  Make sure the entry is long aligned.  Write some padding.  Read in as many entries as possible.  Read in numeric data. *
             * Read string data from the following tags:
             * - tag_filename
             * - tag_artist
             * - tag_album
             * - tag_title
             * 
             * A crc32 hash is calculated from the read data
             * and stored back to the data offset field kept in memory.
              Seek to the end of the string data.  Backup the master index position.  Check if we can resurrect some deleted runtime statistics data.  Read the index entry. *
             * Skip unless the entry is marked as being deleted
             * or the data has already been resurrected.
              Now try to match the entry. *
             * To succesfully match a song, the following conditions
             * must apply:
             * 
             * For numeric fields: tag_length
             * - Full identical match is required
             * 
             * If tag_filename matches, no further checking necessary.
             * 
             * For string hashes: tag_artist, tag_album, tag_title
             * - All three of these must match
              Try to match numeric fields first.  Now it's time to do the hash matching.  No filename match, check if we can match two other tags.  Still no match found, give up.  A match found, now copy & resurrect the statistical data.  Avoid processing this entry again.  Restore the master index position.  Commit the data to the index.  Data has been resurrected.  Write back the updated index. *
 * Return values:
 *     > 0   success
 *    == 0   temporary failure
 *     < 0   fatal error
  Check the number of entries we need to allocate ram for.  Just to be sure we are clean.  Open the index file, which contains the tag names.  First part  Second part  First part  Second part  Allocate buffer for all index entries from both old and new
     * tag files.  Allocate lookup buffer. The first portion of commit_entry_count
     * contains the new tags in the temporary file and the second
     * part for locating entries already in the db.
     * 
     *  New tags  Old tags
     * +---------+---------------------------+
     * |  index  | position/ENTRY_CHUNK_SIZE |  lookup buffer
     * +---------+---------------------------+
     *              
     * Old tags are inserted to a temporary buffer with position:
     *     tempbuf_insert(position/ENTRY_CHUNK_SIZE, ...);
     * And new tags with index:
     *     tempbuf_insert(idx, ...);
     * 
     * The buffer is sorted and written into tag file:
     *     tempbuf_sort(...);
     * leaving master index locations messed up.
     * 
     * That is fixed using the lookup buffer for old tags:
     *     new_seek = tempbuf_find_location(old_seek, ...);
     * and for new tags:
     *     new_seek = tempbuf_find_location(idx);
      And calculate the remaining data space used mainly for storing
     * tag data (strings). *
         * If tag file contains unique tags (sorted index), we will load
         * it entirely into memory so we can resort it later for use with
         * chunked browsing.
          Skip deleted entries. *
                 * Save the tag and tag id in the memory buffer. Tag id
                 * is saved so we can later reindex the master lookup
                 * table when the index gets resorted.
                 *
         * Creating new index file to store the tags. No need to preload
         * anything whether the index type is sorted or not.
          Loading the tag lookup file as "master file".  Write the header (write real values later). *
         * Master file already exists so we need to process the current
         * file first.
         *
         * If we reach end of the master file, we need to expand it to
         * hold new tags. If the current index is not sorted, we can
         * simply append new data to end of the file.
         * However, if the index is sorted, we need to update all tag
         * pointers in the master file for the current index.
         *
     * Load new unique tags in memory to be sorted later and added
     * to the master lookup file.
      h is the header of the temporary file containing new tags.  Read data.  Skip to next.  Sort the buffer data and write it to the index file. *
         * We need to truncate the index file now. There can be junk left
         * at the end of file (however, we _should_ always follow the
         * entry_count and don't crash with that).
         *
         * Now update all indexes in the master lookup file.
          We can just ignore deleted entries.  idxbuf[j].tag_seek[index_type] = 0; Write back the updated index. *
     * Walk through the temporary file containing the new tags.
      build_normal_index(h, tmpfd, masterfd, idx); Read entry headers.  Read data.  Write to index file.  Skip to next.  Locate the correct entry from the sorted array.  Write index.  Finally write the header.  Load the header.  Fully initialize existing headers (if any) before going further.  At first be sure to unload the ramcache!  Beyond here, jump to commit_error to undo locks and restore dircache  Try to steal every buffer we can :)  Suspend dircache to free its allocation.  HAVE_DIRCACHE  HAVE_TC_RAMCACHE  And finally fail if there are no buffers available.  Mark DB dirty so it will stay disabled if commit fails.  Now create the index files.  Update the master index headers.  Reload tagcache.  HAVE_TC_RAMCACHE  HAVE_TC_RAMCACHE  Resume the dircache, if we stole the buffer.  HAVE_DIRCACHE  Re-open the masterfd.  Make sure queue is not full.  Queue is full, try again later...  !__PCTOOL__  Skip all whitespace  Read in tag name  Read in tag data  Find the start.  Read the data.  logf("%d/%s", line_n, buf);  Stop if tag has already been modified.  !__PCTOOL__  Initialize the changelog  Skip until the entry found has been modified.  Skip deleted entries too.  Now retrieve all tags.  At first mark the entry removed from ram cache.  Now check which tags are no longer in use (if any)  Use RAM DB if available for greater speed  Now delete all tags no longer in use. * 
         * Replace tag seek with a hash value of the field string data.
         * That way runtime statistics of moved or altered files can be
         * resurrected.
          protect tfe and seek if crc_32() yield()s  HAVE_TC_RAMCACHE  Open the index file, which contains the tag names.  Skip the header block  Delete from ram.  HAVE_TC_RAMCACHE  Open the index file, which contains the tag names.  Skip the header block  Debug, print 10 first characters of the tag
        read(fd, buf, 10);
        buf[10]='\0';
        logf("TAG:%s", buf);
        lseek(fd, -10, SEEK_CUR);
         Write first data byte in tag as \0  Now tag data has been removed  Write index entry back into master index. *
 * Returns true if there is an event waiting in the queue
 * that requires the current operation to be aborted.
  __PCTOOL__  Load the header. * 
     * Now calculate the required cache size plus 
     * some extra space for alignment fixes. 
      Check the statefile memory placement  Lets allocate real memory and load it  Now fix the pointers  Load the tagcache master header (should match the actual DB file header).  Create the header  And dump the data too  HAVE_EEPROM_SETTINGS  DEBUG: After tagcache commit and dircache rebuild, hdr-sturcture
     * may become corrupt.  Wait for any in-progress dircache build to complete  HAVE_DIRCACHE  lock for the rest of the scan, simpler to handle  Master header copy should already match, this can be redundant to do.  Load the master index table.  Load the tags right after the index entries  Load the header  Load the entries for this tag  Abort if we got a critical event in queue  Load the header for the tag itself  End of lookup table.  dircache reference clobbers *fe  filename NOT optional  We have a special handling for the filename tags; neither the
               paths nor the entry headers are stored; only the tagcache header
               and dircache references are.  This flag must not be used yet.  HAVE_DIRCACHE  seek over tag data instead of reading  If auto updating, check storage too, otherwise simply
                   attempt to load cache references  in cache and we have fileref  not in cache but okay  ndef HAVE_DIRCACHE  Check if path is no longer valid  HAVE_DIRCACHE  0x431 0x4000 0x433 0x00 HAVE_DIRCACHE  HAVE_TC_RAMCACHE  Check if the file has already deleted from the db.  Now check if the file exists.  Note that this function must not be inlined, otherwise the whole point
 * of having the code in a separate function is lost.
  check for a database.ignore file  check for a database.unignore file  max roots on native. on application more can be added via malloc()  check if the path is already included in the search roots, by the
 * means that the path itself or one of its parents folders is in the list  check if the link target is inside of an existing search root
         * don't add if target is inside, we'll scan it later 
 * This adds a path to the search roots, possibly during traveling through
 * the filesystem. It only adds if the path is not inside an already existing
 * search root.
 *
 * Returns true if it added the path to the search roots
 * 
 * Windows 2000 and greater supports symlinks, but they don't provide
 * realpath() or readlink(), and symlinks are rarely used on them so
 * ignore this for windows for now
 * Okay, realpath() is almost completely broken on android
     *
     * It doesn't accept NULL for resolved_name to dynamically allocate
     * the resulting path; and it assumes resolved_name to be PATH_MAX
     * (actually MAXPATHLEN, but it's the same [as of 2.3]) long
     * and blindly writes to the end if it
     *
     * therefore use sufficiently large static storage here
     * Note that PATH_MAX != MAX_PATH
     * get the end of the list  count \0  ok to cast const away here  native, simulator  check for a database.ignore and database.unignore  don't do anything if both ignore and unignore are there  Recursively scan the dir.  don't follow symlinks to dirs, but try to add it as a search root
             * this makes able to avoid looping in recursive symlinks  SIMULATOR  Add a new entry to the temporary db file.  Wait until current path for debug screen is read and unset.  this is called by the database tool to not pull in global_settings  Scan for new files.  i is for the path vector, j for the roots_ll array
     * path can be skipped , but root_ll entries can't  skip this path  check_dir might add new roots  Write the header.  Commit changes to the database.  Import runtime statistics if we just initialized the db.  +1 to ensure NULL sentinel  __PCTOOL__  At first we should load the cache (if exists).  If loading failed, it must indicate some problem with the db
         * so disable it entirely to prevent further issues.  Just to make sure there is no statefile present.  remove(TAGCACHE_STATEFILE); HAVE_TC_RAMCACHE  If the previous cache build/update was interrupted, commit
     * the changes first in foreground.  HAVE_EEPROM_SETTINGS  Allocate space for the tagcache if found on disk.  HAVE_TC_RAMCACHE  Don't delay bootup with the header check but do it on background.  HAVE_RC_RAMCACHE  This will be very slow unless dircache is enabled
                       or target is flash based, but do it anyway for
                       consistency.  Flush the command queue.  HAVE_DIRCACHE  HAVE_TC_RAMCACHE  !__PCTOOL__ **************************************************************************
 *             __________               __   ___.
 *   Open      \______   \ ____   ____ |  | _\_ |__   _______  ___
 *   Source     |       _//  _ \_/ ___\|  |/ /| __ \ /  _ \  \/  /
 *   Jukebox    |    |   (  <_> )  \___|    < | \_\ (  <_> > <  <
 *   Firmware   |____|_  /\____/ \___  >__|_ \|___  /\____/__/\_ \
 *                     \/            \/     \/    \/            \/
 * $Id$
 *
 * Copyright (C) 2005 by Miika Pekkarinen
 *
 * This program is free software; you can redistribute it and/or
 * modify it under the terms of the GNU General Public License
 * as published by the Free Software Foundation; either version 2
 * of the License, or (at your option) any later version.
 *
 * This software is distributed on an "AS IS" basis, WITHOUT WARRANTY OF ANY
 * KIND, either express or implied.
 *
 ***************************************************************************
 *                    TagCache API
 * 
 *       ----------x---------x------------------x-----
 *                 |         |                  |              External
 * +---------------x-------+ |       TagCache   |              Libraries
 * | Modification routines | |         Core     |           
 * +-x---------x-----------+ |                  |           
 *   | (R/W)   |             |                  |           |
 *   |  +------x-------------x-+  +-------------x-----+     |
 *   |  |                      x==x Filters & clauses |     |
 *   |  | Search routines      |  +-------------------+     |
 *   |  |                      x============================x DirCache
 *   |  +-x--------------------+                            | (optional)
 *   |    | (R)                                             |
 *   |    | +-------------------------------+  +---------+  |
 *   |    | | DB Commit (sort,unique,index) |  |         |  |
 *   |    | +-x--------------------------x--+  | Control |  |
 *   |    |   | (R/W)                    | (R) | Thread  |  |
 *   |    |   | +----------------------+ |     |         |  |
 *   |    |   | | TagCache DB Builder  | |     +---------+  |
 *   |    |   | +-x-------------x------+ |                  |
 *   |    |   |   | (R)         | (W)    |                  |
 *   |    |   |   |          +--x--------x---------+        |
 *   |    |   |   |          | Temporary Commit DB |        |
 *   |    |   |   |          +---------------------+        |
 * +-x----x-------x--+                                      |
 * | TagCache RAM DB x==\(W) +-----------------+            |
 * +-----------------+   \===x                 |            |
 *   |    |   |   |      (R) |  Ram DB Loader  x============x DirCache
 * +-x----x---x---x---+   /==x                 |            | (optional)
 * | Tagcache Disk DB x==/   +-----------------+            |  
 * +------------------+                                     |
 * 
 #define LOGF_ENABLE readlink()  PATH_MAX  Tag Cache thread.  Previous path when scanning directory tree recursively.  Used when removing duplicates.  Allocated when needed.  Current location in buffer.  Buffer size (TEMPBUF_SIZE).  Buffer space left.  Tags we want to get sorted (loaded to the tempbuf).  Uniqued tags (we can use these tags with filters and conditional clauses).  String presentation of the tags defined in tagcache.h. Must be in correct order!  Status information of the tagcache.  Queue commands.  Internal tagcache command queue.  Tag database structures.  Variable-length tag entry in tag files.  Length of the data in bytes including '\0'  Corresponding entry location in index file of not unique tags  Begin of the tag data  Fixed-size tag entry in master db index.  Location of tag data or numeric tag data  Status flags  Header is the same in every file.  Header version number  Data size in bytes  Number of entries in this file  Increasing counting number  Number of commits so far  For the endianess correction *
 Note: This should be (1 + TAG_COUNT) amount of l's.
  HAVE_DIRCACHE  Header is created when loading database to ram.  Tag file content (dcfrefs if tag_filename)  Number of entries in the indices.  Master index file content  Statefile version number  Header from the master index  Old load address of hdr for relocation  HAVE_EEPROM_SETTINGS  In-RAM ramcache structure (not persisted)  allocated ramcache_header  buffer handle  ndef HAVE_TC_RAMCACHE  HAVE_TC_RAMCACHE * 
 * Full tag entries stored in a temporary file waiting 
 * for commit to the cache.  Lookup buffer for fixing messed up index while after sorting.  Used when building the temporary file.  Thread safe locking  Yeah, malloc would be really nice now :)  !__PCTOOL__  __PCTOOL__  Helper functions for the two most read/write data structure: tagfile_entry and index_entry  Check the header.  Check the header.  Success.  Trying to read again, this time with endianess correction enabled.  Sorting can lock up for quite a while, so yield occasionally  __PCTOOL__  find the ramcache entry corresponding to the file indicated by
 * filename and dc (it's corresponding dircache id).  Check if tagcache is loaded into ram.  Search references  defined (HAVE_TC_RAMCACHE) && defined (HAVE_DIRCACHE)  Note: Don't use MAX_PATH here, it's too small  APPLICATION  Not found?  HAVE_TC_RAMCACHE  We need to exclude all memory only flags & tags when writing to disk.  Only update numeric data. Writing the whole index to RAM by memcpy
     * destroys dircache pointers!
      Don't touch the dircache flag or attributes.  HAVE_TC_RAMCACHE  !__PCTOOL__  HAVE_DIRCACHE  HAVE_TC_RAMCACHE  Attempt to find tag data through store-to-load forwarding in
           command queue  A straight calculus gives:
                     autoscore = 100 * playtime / length / playcout (1)
                   Now, consider the euclidian division of playtime by length:
                     playtime = alpha * length + beta
                   With:
                     0 <= beta < length
                   Now, (1) becomes:
                     autoscore = 100 * (alpha / playcout + beta / length / playcount)
                   Both terms should be small enough to avoid any overflow
                 How many commits before the file has been added to the DB.  return filename; caller handles basename  FALLTHRU  Go through all conditional clauses.  all conditions before logical-or satisfied --
                      stop processing clauses  str points to movable data, but no locking required here,
                     * as no yield() is following  HAVE_TC_RAMCACHE  Check if entry has been deleted.  Clause failed -- try finding a logical-or clause  Found logical-or?  Check clauses after logical-or  If uniq buffer is not defined we must return true for search to work.  Return false if entry is found.  lock because below makes a pointer to movable data  idx points to movable data, don't yield or reload  Skip deleted files.  Go through all filters..  Check for conditions.  Add to the seek list if not already in uniq buffer (doesn't yield) Lets add it.  HAVE_TC_RAMCACHE  Check if entry has been deleted.  Go through all filters..  Check for conditions.  Add to the seek list if not already in uniq buffer.  Lets add it.  Always open as R/W so we can pass tcs to functions that modify data also
         * without failing.  Check if there is already a similar filter in present (filters are
         * much faster than clauses). 
          Relative fetch.  We need to retrieve flag status for dircache.  Check for end of list.  Try to fetch more.  Direct fetch.  else do it the hard way  HAVE_DIRCACHE  don't return ep->tag_data directly as it may move  was true before we copied to buf too  Increase position for the next run. This may get overwritten.  HAVE_TC_RAMCACHE  Seek stream to the correct position and continue to direct fetch. *
     Update the position for the next read (this may be overridden
     if filters or clauses are being used).
      Write it back  Find the corresponding entry in tagcache.  this macro sets id3 strings by copying to the id3v2buf  initialize with null if tag doesn't exist  defined(HAVE_TC_RAMCACHE) && defined(HAVE_DIRCACHE)  Tag length  GCC 3.4.6 for Coldfire can choose to inline this function. Not a good
 * idea, as it uses lots of stack and is called from a recursive function
 * (check_dir).
  Adding tag  Crude logging for the sim - to aid in debugging  SIMULATOR  Check for overlength file path.  Path can't be shortened.  Check if the file is supported.  Check if the file is already cached.  Be sure the entry doesn't exist.  Check if file has been modified.  TODO: Mark that the index exists (for fast reverse scan) found_idx[idx_id/8] |= idx_id%8; No changes to file.  Metadata might have been changed. Delete the entry.  Track number missing?  Numeric tags  String tags.  Write the header  And tags also... Correct order is critical  Check if the crc does not exist -> entry does not exist for sure.  Insert to CRC buffer.  Insert it to the buffer.  Generate reverse lookup entries.  Fix the lookup list.  Check the chunk alignment.  Make sure the entry is long aligned.  Write some padding.  Read in as many entries as possible.  Read in numeric data. *
             * Read string data from the following tags:
             * - tag_filename
             * - tag_artist
             * - tag_album
             * - tag_title
             * 
             * A crc32 hash is calculated from the read data
             * and stored back to the data offset field kept in memory.
              Seek to the end of the string data.  Backup the master index position.  Check if we can resurrect some deleted runtime statistics data.  Read the index entry. *
             * Skip unless the entry is marked as being deleted
             * or the data has already been resurrected.
              Now try to match the entry. *
             * To succesfully match a song, the following conditions
             * must apply:
             * 
             * For numeric fields: tag_length
             * - Full identical match is required
             * 
             * If tag_filename matches, no further checking necessary.
             * 
             * For string hashes: tag_artist, tag_album, tag_title
             * - All three of these must match
              Try to match numeric fields first.  Now it's time to do the hash matching.  No filename match, check if we can match two other tags.  Still no match found, give up.  A match found, now copy & resurrect the statistical data.  Avoid processing this entry again.  Restore the master index position.  Commit the data to the index.  Data has been resurrected.  Write back the updated index. *
 * Return values:
 *     > 0   success
 *    == 0   temporary failure
 *     < 0   fatal error
  Check the number of entries we need to allocate ram for.  Just to be sure we are clean.  Open the index file, which contains the tag names.  First part  Second part  First part  Second part  Allocate buffer for all index entries from both old and new
     * tag files.  Allocate lookup buffer. The first portion of commit_entry_count
     * contains the new tags in the temporary file and the second
     * part for locating entries already in the db.
     * 
     *  New tags  Old tags
     * +---------+---------------------------+
     * |  index  | position/ENTRY_CHUNK_SIZE |  lookup buffer
     * +---------+---------------------------+
     *              
     * Old tags are inserted to a temporary buffer with position:
     *     tempbuf_insert(position/ENTRY_CHUNK_SIZE, ...);
     * And new tags with index:
     *     tempbuf_insert(idx, ...);
     * 
     * The buffer is sorted and written into tag file:
     *     tempbuf_sort(...);
     * leaving master index locations messed up.
     * 
     * That is fixed using the lookup buffer for old tags:
     *     new_seek = tempbuf_find_location(old_seek, ...);
     * and for new tags:
     *     new_seek = tempbuf_find_location(idx);
      And calculate the remaining data space used mainly for storing
     * tag data (strings). *
         * If tag file contains unique tags (sorted index), we will load
         * it entirely into memory so we can resort it later for use with
         * chunked browsing.
          Skip deleted entries. *
                 * Save the tag and tag id in the memory buffer. Tag id
                 * is saved so we can later reindex the master lookup
                 * table when the index gets resorted.
                 *
         * Creating new index file to store the tags. No need to preload
         * anything whether the index type is sorted or not.
          Loading the tag lookup file as "master file".  Write the header (write real values later). *
         * Master file already exists so we need to process the current
         * file first.
         *
         * If we reach end of the master file, we need to expand it to
         * hold new tags. If the current index is not sorted, we can
         * simply append new data to end of the file.
         * However, if the index is sorted, we need to update all tag
         * pointers in the master file for the current index.
         *
     * Load new unique tags in memory to be sorted later and added
     * to the master lookup file.
      h is the header of the temporary file containing new tags.  Read data.  Skip to next.  Sort the buffer data and write it to the index file. *
         * We need to truncate the index file now. There can be junk left
         * at the end of file (however, we _should_ always follow the
         * entry_count and don't crash with that).
         *
         * Now update all indexes in the master lookup file.
          We can just ignore deleted entries.  idxbuf[j].tag_seek[index_type] = 0; Write back the updated index. *
     * Walk through the temporary file containing the new tags.
      build_normal_index(h, tmpfd, masterfd, idx); Read entry headers.  Read data.  Write to index file.  Skip to next.  Locate the correct entry from the sorted array.  Write index.  Finally write the header.  Load the header.  Fully initialize existing headers (if any) before going further.  At first be sure to unload the ramcache!  Beyond here, jump to commit_error to undo locks and restore dircache  Try to steal every buffer we can :)  Suspend dircache to free its allocation.  HAVE_DIRCACHE  HAVE_TC_RAMCACHE  And finally fail if there are no buffers available.  Mark DB dirty so it will stay disabled if commit fails.  Now create the index files.  Update the master index headers.  Reload tagcache.  HAVE_TC_RAMCACHE  HAVE_TC_RAMCACHE  Resume the dircache, if we stole the buffer.  HAVE_DIRCACHE  Re-open the masterfd.  Make sure queue is not full.  Queue is full, try again later...  !__PCTOOL__  Skip all whitespace  Read in tag name  Read in tag data  Find the start.  Read the data.  logf("%d/%s", line_n, buf);  Stop if tag has already been modified.  !__PCTOOL__  Initialize the changelog  Skip until the entry found has been modified.  Skip deleted entries too.  Now retrieve all tags.  At first mark the entry removed from ram cache.  Now check which tags are no longer in use (if any)  Use RAM DB if available for greater speed  Now delete all tags no longer in use. * 
         * Replace tag seek with a hash value of the field string data.
         * That way runtime statistics of moved or altered files can be
         * resurrected.
          protect tfe and seek if crc_32() yield()s  HAVE_TC_RAMCACHE  Open the index file, which contains the tag names.  Skip the header block  Delete from ram.  HAVE_TC_RAMCACHE  Open the index file, which contains the tag names.  Skip the header block  Debug, print 10 first characters of the tag
        read(fd, buf, 10);
        buf[10]='\0';
        logf("TAG:%s", buf);
        lseek(fd, -10, SEEK_CUR);
         Write first data byte in tag as \0  Now tag data has been removed  Write index entry back into master index. *
 * Returns true if there is an event waiting in the queue
 * that requires the current operation to be aborted.
  __PCTOOL__  Load the header. * 
     * Now calculate the required cache size plus 
     * some extra space for alignment fixes. 
      Check the statefile memory placement  Lets allocate real memory and load it  Now fix the pointers  Load the tagcache master header (should match the actual DB file header).  Create the header  And dump the data too  HAVE_EEPROM_SETTINGS  DEBUG: After tagcache commit and dircache rebuild, hdr-sturcture
     * may become corrupt.  Wait for any in-progress dircache build to complete  HAVE_DIRCACHE  lock for the rest of the scan, simpler to handle  Master header copy should already match, this can be redundant to do.  Load the master index table.  Load the tags right after the index entries  Load the header  Load the entries for this tag  Abort if we got a critical event in queue  Load the header for the tag itself  End of lookup table.  dircache reference clobbers *fe  filename NOT optional  We have a special handling for the filename tags; neither the
               paths nor the entry headers are stored; only the tagcache header
               and dircache references are.  This flag must not be used yet.  HAVE_DIRCACHE  seek over tag data instead of reading  If auto updating, check storage too, otherwise simply
                   attempt to load cache references  in cache and we have fileref  not in cache but okay  ndef HAVE_DIRCACHE  Check if path is no longer valid  HAVE_DIRCACHE  0x431 0x4000 0x433 0x00 HAVE_DIRCACHE  HAVE_TC_RAMCACHE  Check if the file has already deleted from the db.  Now check if the file exists.  Note that this function must not be inlined, otherwise the whole point
 * of having the code in a separate function is lost.
  check for a database.ignore file  check for a database.unignore file  max roots on native. on application more can be added via malloc()  check if the path is already included in the search roots, by the
 * means that the path itself or one of its parents folders is in the list  check if the link target is inside of an existing search root
         * don't add if target is inside, we'll scan it later 
 * This adds a path to the search roots, possibly during traveling through
 * the filesystem. It only adds if the path is not inside an already existing
 * search root.
 *
 * Returns true if it added the path to the search roots
 * 
 * Windows 2000 and greater supports symlinks, but they don't provide
 * realpath() or readlink(), and symlinks are rarely used on them so
 * ignore this for windows for now
 * Okay, realpath() is almost completely broken on android
     *
     * It doesn't accept NULL for resolved_name to dynamically allocate
     * the resulting path; and it assumes resolved_name to be PATH_MAX
     * (actually MAXPATHLEN, but it's the same [as of 2.3]) long
     * and blindly writes to the end if it
     *
     * therefore use sufficiently large static storage here
     * Note that PATH_MAX != MAX_PATH
     * get the end of the list  count \0  ok to cast const away here  native, simulator  check for a database.ignore and database.unignore  don't do anything if both ignore and unignore are there  Recursively scan the dir.  don't follow symlinks to dirs, but try to add it as a search root
             * this makes able to avoid looping in recursive symlinks  SIMULATOR  Add a new entry to the temporary db file.  Wait until current path for debug screen is read and unset.  this is called by the database tool to not pull in global_settings  Scan for new files.  i is for the path vector, j for the roots_ll array
     * path can be skipped , but root_ll entries can't  skip this path  check_dir might add new roots  Write the header.  Commit changes to the database.  Import runtime statistics if we just initialized the db.  +1 to ensure NULL sentinel  __PCTOOL__  At first we should load the cache (if exists).  If loading failed, it must indicate some problem with the db
         * so disable it entirely to prevent further issues.  Just to make sure there is no statefile present.  remove(TAGCACHE_STATEFILE); HAVE_TC_RAMCACHE  If the previous cache build/update was interrupted, commit
     * the changes first in foreground.  HAVE_EEPROM_SETTINGS  Allocate space for the tagcache if found on disk.  HAVE_TC_RAMCACHE  Don't delay bootup with the header check but do it on background.  HAVE_RC_RAMCACHE  This will be very slow unless dircache is enabled
                       or target is flash based, but do it anyway for
                       consistency.  Flush the command queue.  HAVE_DIRCACHE  HAVE_TC_RAMCACHE  !__PCTOOL__ **************************************************************************
 *             __________               __   ___.
 *   Open      \______   \ ____   ____ |  | _\_ |__   _______  ___
 *   Source     |       _//  _ \_/ ___\|  |/ /| __ \ /  _ \  \/  /
 *   Jukebox    |    |   (  <_> )  \___|    < | \_\ (  <_> > <  <
 *   Firmware   |____|_  /\____/ \___  >__|_ \|___  /\____/__/\_ \
 *                     \/            \/     \/    \/            \/
 * $Id$
 *
 * Copyright (C) 2005 by Miika Pekkarinen
 *
 * This program is free software; you can redistribute it and/or
 * modify it under the terms of the GNU General Public License
 * as published by the Free Software Foundation; either version 2
 * of the License, or (at your option) any later version.
 *
 * This software is distributed on an "AS IS" basis, WITHOUT WARRANTY OF ANY
 * KIND, either express or implied.
 *
 ***************************************************************************
 *                    TagCache API
 * 
 *       ----------x---------x------------------x-----
 *                 |         |                  |              External
 * +---------------x-------+ |       TagCache   |              Libraries
 * | Modification routines | |         Core     |           
 * +-x---------x-----------+ |                  |           
 *   | (R/W)   |             |                  |           |
 *   |  +------x-------------x-+  +-------------x-----+     |
 *   |  |                      x==x Filters & clauses |     |
 *   |  | Search routines      |  +-------------------+     |
 *   |  |                      x============================x DirCache
 *   |  +-x--------------------+                            | (optional)
 *   |    | (R)                                             |
 *   |    | +-------------------------------+  +---------+  |
 *   |    | | DB Commit (sort,unique,index) |  |         |  |
 *   |    | +-x--------------------------x--+  | Control |  |
 *   |    |   | (R/W)                    | (R) | Thread  |  |
 *   |    |   | +----------------------+ |     |         |  |
 *   |    |   | | TagCache DB Builder  | |     +---------+  |
 *   |    |   | +-x-------------x------+ |                  |
 *   |    |   |   | (R)         | (W)    |                  |
 *   |    |   |   |          +--x--------x---------+        |
 *   |    |   |   |          | Temporary Commit DB |        |
 *   |    |   |   |          +---------------------+        |
 * +-x----x-------x--+                                      |
 * | TagCache RAM DB x==\(W) +-----------------+            |
 * +-----------------+   \===x                 |            |
 *   |    |   |   |      (R) |  Ram DB Loader  x============x DirCache
 * +-x----x---x---x---+   /==x                 |            | (optional)
 * | Tagcache Disk DB x==/   +-----------------+            |  
 * +------------------+                                     |
 * 
 #define LOGF_ENABLE readlink()  PATH_MAX  Tag Cache thread.  Previous path when scanning directory tree recursively.  Used when removing duplicates.  Allocated when needed.  Current location in buffer.  Buffer size (TEMPBUF_SIZE).  Buffer space left.  Tags we want to get sorted (loaded to the tempbuf).  Uniqued tags (we can use these tags with filters and conditional clauses).  String presentation of the tags defined in tagcache.h. Must be in correct order!  Status information of the tagcache.  Queue commands.  Internal tagcache command queue.  Tag database structures.  Variable-length tag entry in tag files.  Length of the data in bytes including '\0'  Corresponding entry location in index file of not unique tags  Begin of the tag data  Fixed-size tag entry in master db index.  Location of tag data or numeric tag data  Status flags  Header is the same in every file.  Header version number  Data size in bytes  Number of entries in this file  Increasing counting number  Number of commits so far  For the endianess correction *
 Note: This should be (1 + TAG_COUNT) amount of l's.
  HAVE_DIRCACHE  Header is created when loading database to ram.  Tag file content (dcfrefs if tag_filename)  Number of entries in the indices.  Master index file content  Statefile version number  Header from the master index  Old load address of hdr for relocation  HAVE_EEPROM_SETTINGS  In-RAM ramcache structure (not persisted)  allocated ramcache_header  buffer handle  ndef HAVE_TC_RAMCACHE  HAVE_TC_RAMCACHE * 
 * Full tag entries stored in a temporary file waiting 
 * for commit to the cache.  Lookup buffer for fixing messed up index while after sorting.  Used when building the temporary file.  Thread safe locking  Yeah, malloc would be really nice now :)  !__PCTOOL__  __PCTOOL__  Helper functions for the two most read/write data structure: tagfile_entry and index_entry  Check the header.  Check the header.  Success.  Trying to read again, this time with endianess correction enabled.  Sorting can lock up for quite a while, so yield occasionally  __PCTOOL__  find the ramcache entry corresponding to the file indicated by
 * filename and dc (it's corresponding dircache id).  Check if tagcache is loaded into ram.  Search references  defined (HAVE_TC_RAMCACHE) && defined (HAVE_DIRCACHE)  Note: Don't use MAX_PATH here, it's too small  APPLICATION  Not found?  HAVE_TC_RAMCACHE  We need to exclude all memory only flags & tags when writing to disk.  Only update numeric data. Writing the whole index to RAM by memcpy
     * destroys dircache pointers!
      Don't touch the dircache flag or attributes.  HAVE_TC_RAMCACHE  !__PCTOOL__  HAVE_DIRCACHE  HAVE_TC_RAMCACHE  Attempt to find tag data through store-to-load forwarding in
           command queue  A straight calculus gives:
                     autoscore = 100 * playtime / length / playcout (1)
                   Now, consider the euclidian division of playtime by length:
                     playtime = alpha * length + beta
                   With:
                     0 <= beta < length
                   Now, (1) becomes:
                     autoscore = 100 * (alpha / playcout + beta / length / playcount)
                   Both terms should be small enough to avoid any overflow
                 How many commits before the file has been added to the DB.  return filename; caller handles basename  FALLTHRU  Go through all conditional clauses.  all conditions before logical-or satisfied --
                      stop processing clauses  str points to movable data, but no locking required here,
                     * as no yield() is following  HAVE_TC_RAMCACHE  Check if entry has been deleted.  Clause failed -- try finding a logical-or clause  Found logical-or?  Check clauses after logical-or  If uniq buffer is not defined we must return true for search to work.  Return false if entry is found.  lock because below makes a pointer to movable data  idx points to movable data, don't yield or reload  Skip deleted files.  Go through all filters..  Check for conditions.  Add to the seek list if not already in uniq buffer (doesn't yield) Lets add it.  HAVE_TC_RAMCACHE  Check if entry has been deleted.  Go through all filters..  Check for conditions.  Add to the seek list if not already in uniq buffer.  Lets add it.  Always open as R/W so we can pass tcs to functions that modify data also
         * without failing.  Check if there is already a similar filter in present (filters are
         * much faster than clauses). 
          Relative fetch.  We need to retrieve flag status for dircache.  Check for end of list.  Try to fetch more.  Direct fetch.  else do it the hard way  HAVE_DIRCACHE  don't return ep->tag_data directly as it may move  was true before we copied to buf too  Increase position for the next run. This may get overwritten.  HAVE_TC_RAMCACHE  Seek stream to the correct position and continue to direct fetch. *
     Update the position for the next read (this may be overridden
     if filters or clauses are being used).
      Write it back  Find the corresponding entry in tagcache.  this macro sets id3 strings by copying to the id3v2buf  initialize with null if tag doesn't exist  defined(HAVE_TC_RAMCACHE) && defined(HAVE_DIRCACHE)  Tag length  GCC 3.4.6 for Coldfire can choose to inline this function. Not a good
 * idea, as it uses lots of stack and is called from a recursive function
 * (check_dir).
  Adding tag  Crude logging for the sim - to aid in debugging  SIMULATOR  Check for overlength file path.  Path can't be shortened.  Check if the file is supported.  Check if the file is already cached.  Be sure the entry doesn't exist.  Check if file has been modified.  TODO: Mark that the index exists (for fast reverse scan) found_idx[idx_id/8] |= idx_id%8; No changes to file.  Metadata might have been changed. Delete the entry.  Track number missing?  Numeric tags  String tags.  Write the header  And tags also... Correct order is critical  Check if the crc does not exist -> entry does not exist for sure.  Insert to CRC buffer.  Insert it to the buffer.  Generate reverse lookup entries.  Fix the lookup list.  Check the chunk alignment.  Make sure the entry is long aligned.  Write some padding.  Read in as many entries as possible.  Read in numeric data. *
             * Read string data from the following tags:
             * - tag_filename
             * - tag_artist
             * - tag_album
             * - tag_title
             * 
             * A crc32 hash is calculated from the read data
             * and stored back to the data offset field kept in memory.
              Seek to the end of the string data.  Backup the master index position.  Check if we can resurrect some deleted runtime statistics data.  Read the index entry. *
             * Skip unless the entry is marked as being deleted
             * or the data has already been resurrected.
              Now try to match the entry. *
             * To succesfully match a song, the following conditions
             * must apply:
             * 
             * For numeric fields: tag_length
             * - Full identical match is required
             * 
             * If tag_filename matches, no further checking necessary.
             * 
             * For string hashes: tag_artist, tag_album, tag_title
             * - All three of these must match
              Try to match numeric fields first.  Now it's time to do the hash matching.  No filename match, check if we can match two other tags.  Still no match found, give up.  A match found, now copy & resurrect the statistical data.  Avoid processing this entry again.  Restore the master index position.  Commit the data to the index.  Data has been resurrected.  Write back the updated index. *
 * Return values:
 *     > 0   success
 *    == 0   temporary failure
 *     < 0   fatal error
  Check the number of entries we need to allocate ram for.  Just to be sure we are clean.  Open the index file, which contains the tag names.  First part  Second part  First part  Second part  Allocate buffer for all index entries from both old and new
     * tag files.  Allocate lookup buffer. The first portion of commit_entry_count
     * contains the new tags in the temporary file and the second
     * part for locating entries already in the db.
     * 
     *  New tags  Old tags
     * +---------+---------------------------+
     * |  index  | position/ENTRY_CHUNK_SIZE |  lookup buffer
     * +---------+---------------------------+
     *              
     * Old tags are inserted to a temporary buffer with position:
     *     tempbuf_insert(position/ENTRY_CHUNK_SIZE, ...);
     * And new tags with index:
     *     tempbuf_insert(idx, ...);
     * 
     * The buffer is sorted and written into tag file:
     *     tempbuf_sort(...);
     * leaving master index locations messed up.
     * 
     * That is fixed using the lookup buffer for old tags:
     *     new_seek = tempbuf_find_location(old_seek, ...);
     * and for new tags:
     *     new_seek = tempbuf_find_location(idx);
      And calculate the remaining data space used mainly for storing
     * tag data (strings). *
         * If tag file contains unique tags (sorted index), we will load
         * it entirely into memory so we can resort it later for use with
         * chunked browsing.
          Skip deleted entries. *
                 * Save the tag and tag id in the memory buffer. Tag id
                 * is saved so we can later reindex the master lookup
                 * table when the index gets resorted.
                 *
         * Creating new index file to store the tags. No need to preload
         * anything whether the index type is sorted or not.
          Loading the tag lookup file as "master file".  Write the header (write real values later). *
         * Master file already exists so we need to process the current
         * file first.
         *
         * If we reach end of the master file, we need to expand it to
         * hold new tags. If the current index is not sorted, we can
         * simply append new data to end of the file.
         * However, if the index is sorted, we need to update all tag
         * pointers in the master file for the current index.
         *
     * Load new unique tags in memory to be sorted later and added
     * to the master lookup file.
      h is the header of the temporary file containing new tags.  Read data.  Skip to next.  Sort the buffer data and write it to the index file. *
         * We need to truncate the index file now. There can be junk left
         * at the end of file (however, we _should_ always follow the
         * entry_count and don't crash with that).
         *
         * Now update all indexes in the master lookup file.
          We can just ignore deleted entries.  idxbuf[j].tag_seek[index_type] = 0; Write back the updated index. *
     * Walk through the temporary file containing the new tags.
      build_normal_index(h, tmpfd, masterfd, idx); Read entry headers.  Read data.  Write to index file.  Skip to next.  Locate the correct entry from the sorted array.  Write index.  Finally write the header.  Load the header.  Fully initialize existing headers (if any) before going further.  At first be sure to unload the ramcache!  Beyond here, jump to commit_error to undo locks and restore dircache  Try to steal every buffer we can :)  Suspend dircache to free its allocation.  HAVE_DIRCACHE  HAVE_TC_RAMCACHE  And finally fail if there are no buffers available.  Mark DB dirty so it will stay disabled if commit fails.  Now create the index files.  Update the master index headers.  Reload tagcache.  HAVE_TC_RAMCACHE  HAVE_TC_RAMCACHE  Resume the dircache, if we stole the buffer.  HAVE_DIRCACHE  Re-open the masterfd.  Make sure queue is not full.  Queue is full, try again later...  !__PCTOOL__  Skip all whitespace  Read in tag name  Read in tag data  Find the start.  Read the data.  logf("%d/%s", line_n, buf);  Stop if tag has already been modified.  !__PCTOOL__  Initialize the changelog  Skip until the entry found has been modified.  Skip deleted entries too.  Now retrieve all tags.  At first mark the entry removed from ram cache.  Now check which tags are no longer in use (if any)  Use RAM DB if available for greater speed  Now delete all tags no longer in use. * 
         * Replace tag seek with a hash value of the field string data.
         * That way runtime statistics of moved or altered files can be
         * resurrected.
          protect tfe and seek if crc_32() yield()s  HAVE_TC_RAMCACHE  Open the index file, which contains the tag names.  Skip the header block  Delete from ram.  HAVE_TC_RAMCACHE  Open the index file, which contains the tag names.  Skip the header block  Debug, print 10 first characters of the tag
        read(fd, buf, 10);
        buf[10]='\0';
        logf("TAG:%s", buf);
        lseek(fd, -10, SEEK_CUR);
         Write first data byte in tag as \0  Now tag data has been removed  Write index entry back into master index. *
 * Returns true if there is an event waiting in the queue
 * that requires the current operation to be aborted.
  __PCTOOL__  Load the header. * 
     * Now calculate the required cache size plus 
     * some extra space for alignment fixes. 
      Check the statefile memory placement  Lets allocate real memory and load it  Now fix the pointers  Load the tagcache master header (should match the actual DB file header).  Create the header  And dump the data too  HAVE_EEPROM_SETTINGS  DEBUG: After tagcache commit and dircache rebuild, hdr-sturcture
     * may become corrupt.  Wait for any in-progress dircache build to complete  HAVE_DIRCACHE  lock for the rest of the scan, simpler to handle  Master header copy should already match, this can be redundant to do.  Load the master index table.  Load the tags right after the index entries  Load the header  Load the entries for this tag  Abort if we got a critical event in queue  Load the header for the tag itself  End of lookup table.  dircache reference clobbers *fe  filename NOT optional  We have a special handling for the filename tags; neither the
               paths nor the entry headers are stored; only the tagcache header
               and dircache references are.  This flag must not be used yet.  HAVE_DIRCACHE  seek over tag data instead of reading  If auto updating, check storage too, otherwise simply
                   attempt to load cache references  in cache and we have fileref  not in cache but okay  ndef HAVE_DIRCACHE  Check if path is no longer valid  HAVE_DIRCACHE  0x431 0x4000 0x433 0x00 HAVE_DIRCACHE  HAVE_TC_RAMCACHE  Check if the file has already deleted from the db.  Now check if the file exists.  Note that this function must not be inlined, otherwise the whole point
 * of having the code in a separate function is lost.
  check for a database.ignore file  check for a database.unignore file  max roots on native. on application more can be added via malloc()  check if the path is already included in the search roots, by the
 * means that the path itself or one of its parents folders is in the list  check if the link target is inside of an existing search root
         * don't add if target is inside, we'll scan it later 
 * This adds a path to the search roots, possibly during traveling through
 * the filesystem. It only adds if the path is not inside an already existing
 * search root.
 *
 * Returns true if it added the path to the search roots
 * 
 * Windows 2000 and greater supports symlinks, but they don't provide
 * realpath() or readlink(), and symlinks are rarely used on them so
 * ignore this for windows for now
 * Okay, realpath() is almost completely broken on android
     *
     * It doesn't accept NULL for resolved_name to dynamically allocate
     * the resulting path; and it assumes resolved_name to be PATH_MAX
     * (actually MAXPATHLEN, but it's the same [as of 2.3]) long
     * and blindly writes to the end if it
     *
     * therefore use sufficiently large static storage here
     * Note that PATH_MAX != MAX_PATH
     * get the end of the list  count \0  ok to cast const away here  native, simulator  check for a database.ignore and database.unignore  don't do anything if both ignore and unignore are there  Recursively scan the dir.  don't follow symlinks to dirs, but try to add it as a search root
             * this makes able to avoid looping in recursive symlinks  SIMULATOR  Add a new entry to the temporary db file.  Wait until current path for debug screen is read and unset.  this is called by the database tool to not pull in global_settings  Scan for new files.  i is for the path vector, j for the roots_ll array
     * path can be skipped , but root_ll entries can't  skip this path  check_dir might add new roots  Write the header.  Commit changes to the database.  Import runtime statistics if we just initialized the db.  +1 to ensure NULL sentinel  __PCTOOL__  At first we should load the cache (if exists).  If loading failed, it must indicate some problem with the db
         * so disable it entirely to prevent further issues.  Just to make sure there is no statefile present.  remove(TAGCACHE_STATEFILE); HAVE_TC_RAMCACHE  If the previous cache build/update was interrupted, commit
     * the changes first in foreground.  HAVE_EEPROM_SETTINGS  Allocate space for the tagcache if found on disk.  HAVE_TC_RAMCACHE  Don't delay bootup with the header check but do it on background.  HAVE_RC_RAMCACHE  This will be very slow unless dircache is enabled
                       or target is flash based, but do it anyway for
                       consistency.  Flush the command queue.  HAVE_DIRCACHE  HAVE_TC_RAMCACHE  !__PCTOOL__ 