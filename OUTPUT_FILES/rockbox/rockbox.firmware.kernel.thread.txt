**************************************************************************
 *             __________               __   ___.
 *   Open      \______   \ ____   ____ |  | _\_ |__   _______  ___
 *   Source     |       _//  _ \_/ ___\|  |/ /| __ \ /  _ \  \/  /
 *   Jukebox    |    |   (  <_> )  \___|    < | \_\ (  <_> > <  <
 *   Firmware   |____|_  /\____/ \___  >__|_ \|___  /\____/__/\_ \
 *                     \/            \/     \/    \/            \/
 * $Id$
 *
 * Copyright (C) 2002 by Ulf Ralberg
 *
 * This program is free software; you can redistribute it and/or
 * modify it under the terms of the GNU General Public License
 * as published by the Free Software Foundation; either version 2
 * of the License, or (at your option) any later version.
 *
 * This software is distributed on an "AS IS" basis, WITHOUT WARRANTY OF ANY
 * KIND, either express or implied.
 *
 ***************************************************************************
 * The sp check in glibc __longjmp_chk() will cause
 * a fatal error when switching threads via longjmp().
  Define THREAD_EXTRA_CHECKS as 1 to enable additional state checks  Always 1 for DEBUG ***************************************************************************
 *                              ATTENTION!!                                 *
 *    See notes below on implementing processor-specific portions!          *
 ****************************************************************************
 *
 * General locking order to guarantee progress. Order must be observed but
 * all stages are not nescessarily obligatory. Going from 1) to 3) is
 * perfectly legal.
 *
 * 1) IRQ
 * This is first because of the likelyhood of having an interrupt occur that
 * also accesses one of the objects farther down the list. Any non-blocking
 * synchronization done may already have a lock on something during normal
 * execution and if an interrupt handler running on the same processor as
 * the one that has the resource locked were to attempt to access the
 * resource, the interrupt handler would wait forever waiting for an unlock
 * that will never happen. There is no danger if the interrupt occurs on
 * a different processor because the one that has the lock will eventually
 * unlock and the other processor's handler may proceed at that time. Not
 * nescessary when the resource in question is definitely not available to
 * interrupt handlers.
 *
 * 2) Kernel Object
 * 1) May be needed beforehand if the kernel object allows dual-use such as
 * event queues. The kernel object must have a scheme to protect itself from
 * access by another processor and is responsible for serializing the calls
 * to block_thread  and wakeup_thread both to themselves and to each other.
 * Objects' queues are also protected here.
 *
 * 3) Thread Slot
 * This locks access to the thread's slot such that its state cannot be
 * altered by another processor when a state change is in progress such as
 * when it is in the process of going on a blocked list. An attempt to wake
 * a thread while it is still blocking will likely desync its state with
 * the other resources used for that state.
 *
 * 4) Core Lists
 * These lists are specific to a particular processor core and are accessible
 * by all processor cores and interrupt handlers. The running (rtr) list is
 * the prime example where a thread may be added by any means.
 ---------------------------------------------------------------------------
 * Processor specific: core_sleep/core_wake/misc. notes
 *
 * ARM notes:
 * FIQ is not dealt with by the scheduler code and is simply restored if it
 * must by masked for some reason - because threading modifies a register
 * that FIQ may also modify and there's no way to accomplish it atomically.
 * s3c2440 is such a case.
 *
 * Audio interrupts are generally treated at a higher priority than others
 * usage of scheduler code with interrupts higher than HIGHEST_IRQ_LEVEL
 * are not in general safe. Special cases may be constructed on a per-
 * source basis and blocking operations are not available.
 *
 * core_sleep procedure to implement for any CPU to ensure an asychronous
 * wakup never results in requiring a wait until the next tick (up to
 * 10000uS!). May require assembly and careful instruction ordering.
 *
 * 1) On multicore, stay awake if directed to do so by another. If so, goto
 *    step 4.
 * 2) If processor requires, atomically reenable interrupts and perform step
 *    3.
 * 3) Sleep the CPU core. If wakeup itself enables interrupts (stop #0x2000
 *    on Coldfire) goto step 5.
 * 4) Enable interrupts.
 * 5) Exit procedure.
 *
 * core_wake and multprocessor notes for sleep/wake coordination:
 * If possible, to wake up another processor, the forcing of an interrupt on
 * the woken core by the waker core is the easiest way to ensure a non-
 * delayed wake and immediate execution of any woken threads. If that isn't
 * available then some careful non-blocking synchonization is needed (as on
 * PP targets at the moment).
 *---------------------------------------------------------------------------
 *
 *
 *---------------------------------------------------------------------------
 * Priority distribution structure (one category for each possible priority):
 *
 *       +----+----+----+ ... +------+
 * hist: | F0 | F1 | F2 |     | Fn-1 |
 *       +----+----+----+ ... +------+
 * mask: | b0 | b1 | b2 |     | bn-1 |
 *       +----+----+----+ ... +------+
 *
 * F = count of threads at priority category n (frequency)
 * b = bitmask of non-zero priority categories (occupancy)
 *
 *        / if H[n] != 0 : 1
 * b[n] = |
 *        \ else         : 0
 *
 *---------------------------------------------------------------------------
 * Basic priority inheritance priotocol (PIP):
 *
 * Mn = mutex n, Tn = thread n
 *
 * A lower priority thread inherits the priority of the highest priority
 * thread blocked waiting for it to complete an action (such as release a
 * mutex or respond to a message via queue_send):
 *
 * 1) T2->M1->T1
 *
 * T1 owns M1, T2 is waiting for M1 to realease M1. If T2 has a higher
 * priority than T1 then T1 inherits the priority of T2.
 *
 * 2) T3
 *    \/
 *    T2->M1->T1
 *
 * Situation is like 1) but T2 and T3 are both queued waiting for M1 and so
 * T1 inherits the higher of T2 and T3.
 *
 * 3) T3->M2->T2->M1->T1
 *
 * T1 owns M1, T2 owns M2. If T3 has a higher priority than both T1 and T2,
 * then T1 inherits the priority of T3 through T2.
 *
 * Blocking chains can grow arbitrarily complex (though it's best that they
 * not form at all very often :) and build-up from these units.
 *---------------------------------------------------------------------------
 ***************************************************************************
 * Processor/OS-specific section - include necessary core support
  CPU_PP 
 * End Processor-specific section
 ************************************************************************** THREAD_EXTRA_CHECKS  Thread locking  NUM_CORES == 1 NUM_CORES  RTR list  !HAVE_PRIORITY_SCHEDULING  HAVE_PRIORITY_SCHEDULING  Forget about it if different CPU  Just woke something therefore a thread is on the run queue  There is a thread ready to run of higher priority on the same
     * core as the current one; recommend a task switch.  HAVE_PRIORITY_SCHEDULING ---------------------------------------------------------------------------
 * Increment frequency at category "priority"
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Decrement frequency at category "priority"
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Remove from one category and add to another
 *---------------------------------------------------------------------------
  HAVE_PRIORITY_SCHEDULING ---------------------------------------------------------------------------
 * Common init for new thread basic info
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Move a thread onto the core's run queue and promote it
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Remove a thread from the core's run queue
 *---------------------------------------------------------------------------
  Does not demote state ---------------------------------------------------------------------------
 * Move a thread back to a running state on its core
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Locks the thread registered as the owner of the block and makes sure it
 * didn't change in the meantime
 *---------------------------------------------------------------------------
  NUM_CORES > 1  The blocker thread may change during the process of trying to
       capture it  TRY, or else deadlocks are possible  Still multi  NUM_CORES  NUM_CORES > 1---------------------------------------------------------------------------
 * Change the priority and rtr entry for a running thread
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Finds the highest priority thread in a list of threads. If the list is
 * empty, the PRIORITY_IDLE is returned.
 *
 * It is possible to use the struct priority_distribution within an object
 * instead of scanning the remaining threads in the list but as a compromise,
 * the resulting per-object memory overhead is saved at a slight speed
 * penalty under high contention.
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Register priority with blocking system and bubble it down the chain if
 * any until we reach the end or something is already equal or higher.
 *
 * NOTE: A simultaneous circular wait could spin deadlock on multiprocessor
 * targets but that same action also guarantees a circular block anyway and
 * those are prevented, right? :-)
 *---------------------------------------------------------------------------
  Multiple owners  Recurse down the all the branches of this; it's the only way.
               We might meet the same queue several times if more than one of
               these threads is waiting the same queue. That isn't a problem
               for us since we early-terminate, just notable.  To see the change each time  Update blocker thread inheritance record  No blocker thread priority change  Running: last in chain  Blocker is blocked  Block doesn't support PIP  Full circle - deadlock!  Blocker becomes current thread and the process repeats  Adjust this wait queue  Queue priority not changing ---------------------------------------------------------------------------
 * Quick-inherit of priority elevation. 'thread' must be not runnable
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Quick-disinherit of priority elevation. 'thread' must current
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Transfer ownership from a single owner to a multi-owner splay from a wait
 * queue
 *---------------------------------------------------------------------------
  All threads will have the same blocker and queue; only we are changing
       it now  The first thread is already locked and is assumed tagged "multi"  Multiple versions of the wait queue may be seen if doing more than
       one thread; queue removal isn't destructive to the pointers of the node
       being removed; this may lead to the blocker priority being wrong for a
       time but it gets fixed up below after getting exclusive access to the
       queue  Locking order reverses here since the threads are no longer on the
       queued side  Becomes a simple, direct transfer ---------------------------------------------------------------------------
 * Transfer ownership to a thread waiting for an objects and transfer
 * inherited priority boost from other waiters. This algorithm knows that
 * blocking chains may only unblock from the very end.
 *
 * Only the owning thread itself may call this and so the assumption that
 * it is the running thread is made.
 *---------------------------------------------------------------------------
  Waking thread inherits priority boost from object owner (blt)  Remove the object's boost from the owning thread  Expected shortcut - no more waiters  If thread is at the blocker priority, its removal may drop it  This thread pwns  Save highest blocked priority ---------------------------------------------------------------------------
 * Readjust priorities when waking a thread blocked waiting for another
 * in essence "releasing" the thread's effect on the object owner. Can be
 * performed from any context.
 *---------------------------------------------------------------------------
  Off to see the wizard...  Queue priority won't change  Blocker priority won't change  HAVE_PRIORITY_SCHEDULING ---------------------------------------------------------------------------
 * Explicitly wakeup a thread on a blocking queue. Only effects threads of
 * STATE_BLOCKED and STATE_BLOCKED_W_TMO.
 *
 * INTERNAL: Intended for use by kernel and not programs.
 *---------------------------------------------------------------------------
  Determine thread's current state.  Threads with PIP blockers cannot specify "WAKEUP_DEFAULT"  Call the specified unblocking PIP (does the rest)  HAVE_PRIORITY_SCHEDULING  timed out ---------------------------------------------------------------------------
 * Check the core's timeout list when at least one thread is due to wake.
 * Filtering for the condition is done before making the call. Resets the
 * tick when the next check will occur.
 *---------------------------------------------------------------------------
  snapshot the current tick  minimum duration: once/minute  If there are no processes waiting for a timeout, just keep the check
       tick from falling into the past.  Break the loop once we have walked through the list of all
     * sleeping processes or have removed them all.  Check sleeping threads. Allow interrupts between checks.  Lock thread slot against explicit wakeup  Timeout still pending - this will be the usual case  Move the next check up to its time  TODO: there are no priority-inheriting timeout blocks
               right now but the procedure should be established  Sleep timeout has been reached / garbage collect stale list
               items  removed this one - prev doesn't change ---------------------------------------------------------------------------
 * Prepares a the current thread to sleep forever or for the given duration.
 *---------------------------------------------------------------------------
  Remove the thread from the list of running threads.  Sleep may expire.  Report new state. ---------------------------------------------------------------------------
 * Switch thread in round robin fashion for any given priority. Any thread
 * that removed itself from the running list first must specify itself in
 * the paramter.
 *
 * INTERNAL: Intended for use by kernel and not programs.
 *---------------------------------------------------------------------------
  Check core_ctx buflib integrity  Check if the current thread stack is overflown  TODO: make a real idle task  Check for expired timeouts  Enter sleep mode to reduce power usage  Awakened by interrupt or other CPU  Select the new task based on priorities and the last time a
     * process got CPU time relative to the highest priority runnable
     * task. If priority is not a feature, then FCFS is used (above).  This ridiculously simple method of aging seems to work
         * suspiciously well. It does tend to reward CPU hogs (under
         * yielding) but that's generally not desirable at all. On
         * the plus side, it, relatively to other threads, penalizes
         * excess yielding which is good if some high priority thread
         * is performing no useful work such as polling for a device
         * to be ready. Of course, aging is only employed when higher
         * and lower priority threads are runnable. The highest
         * priority runnable thread(s) are never skipped unless a
         * lower-priority process has aged sufficiently. Priorities
         * of REALTIME class are run strictly according to priority
         * thus are not subject to switchout due to lower-priority
         * processes aging; they must give up the processor by going
         * off the run list.  Reset aging counter  HAVE_PRIORITY_SCHEDULING  And finally, give control to the next thread. ---------------------------------------------------------------------------
 * Sleeps a thread for at least a specified number of ticks with zero being
 * a wait until the next tick.
 *
 * INTERNAL: Intended for use by kernel and not programs.
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Block a thread on a blocking queue for explicit wakeup. If timeout is
 * negative, the block is infinite.
 *
 * INTERNAL: Intended for use by kernel and not programs.
 *---------------------------------------------------------------------------
  HAVE_PRIORITY_SCHEDULING  Queue priority won't change  HAVE_PRIORITY_SCHEDULING ---------------------------------------------------------------------------
 * Place the current core in idle mode - woken up on interrupt or wake
 * request from another core.
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Create a thread. If using a dual core architecture, specify which core to
 * start the thread on.
 *
 * Return ID if context area could be allocated, else NULL.
 *---------------------------------------------------------------------------
  Munge the stack to make it easy to spot stack overflows  Writeback stack munging or anything else before starting  Snapshot while locked ---------------------------------------------------------------------------
 * Block the current thread until another thread terminates. A thread may
 * wait on itself to terminate but that will deadlock
 *.
 * Parameter is the ID as returned from create_thread().
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Exit the current thread
 *---------------------------------------------------------------------------
  Slot is no longer this thread  No longer using resources from creator  This should never and must never be reached - if it is, the
     * state is corrupted  Cancel CPU boost if any  Only one bit in the mask should be set with a frequency on 1 which
     * represents the thread's own base priority otherwise threads are waiting
     * on an abandoned object  HAVE_PRIORITY_SCHEDULING  Remove from scheduler lists  No switch_thread context save  Do final release of resources and remove the thread ---------------------------------------------------------------------------
 * Sets the thread's relative base priority for the core it runs on. Any
 * needed inheritance changes also may happen.
 *---------------------------------------------------------------------------
  Invalid priority argument  Invalid thread  No base priority change  Adjust the thread's priority influence on itself  No running priority change  This thread is running - just change location on the run queue.
           Also sets thread->priority.  Thread is blocked  End of transitive blocks ---------------------------------------------------------------------------
 * Returns the current base priority for a thread.
 *---------------------------------------------------------------------------
  Simply check without locking slot. It may or may not be valid by the
     * time the function returns anyway. If all tests pass, it is the
     * correct value for when it was valid.  HAVE_PRIORITY_SCHEDULING ---------------------------------------------------------------------------
 * Starts a frozen thread - similar semantics to wakeup_thread except that
 * the thread is on no scheduler or wakeup queue at all. It exists simply by
 * virtue of the slot having a state of STATE_FROZEN.
 *---------------------------------------------------------------------------
  If thread is the current one, it cannot be frozen, therefore
     * there is no need to check that. ---------------------------------------------------------------------------
 * Switch the processor that the currently executing thread runs on.
 *---------------------------------------------------------------------------
  Old core won't be using slot resources at this point  not reached  No change  Remove us from old core lists  No switch_thread context save  Do the actual migration  Executing on new core  NUM_CORES > 1 ---------------------------------------------------------------------------
 * Change the boost state of a thread boosting or unboosting the CPU
 * as required.
 *---------------------------------------------------------------------------
  HAVE_SCHEDULER_BOOSTCTRL ---------------------------------------------------------------------------
 * Initialize threading API. This assumes interrupts are not yet enabled. On
 * multicore setups, no core is allowed to proceed until create_thread calls
 * are safe to perform.
 *---------------------------------------------------------------------------
  before using cores!  Create main thread  WTF? There really must be a slot available at this stage.
             * This can fail if, for example, .bss isn't zero'ed out by the
             * loader or threads is in the wrong section.  Boot CPU:
     * Wait for other processors to finish their inits since create_thread
     * isn't safe to call until the kernel inits are done. The first
     * threads created in the system must of course be created by CPU.
     * Another possible approach is to initialize all cores and slots
     * for each core by CPU, let the remainder proceed in parallel and
     * signal CPU when all are finished.
     *
     * Other:
     * After last processor completes, it should signal all others to
     * proceed or may signal the next and call thread_exit(). The last one
     * to finish will signal CPU.
      No main thread on coprocessors - go idle and wait  NUM_CORES **************************************************************************
 *             __________               __   ___.
 *   Open      \______   \ ____   ____ |  | _\_ |__   _______  ___
 *   Source     |       _//  _ \_/ ___\|  |/ /| __ \ /  _ \  \/  /
 *   Jukebox    |    |   (  <_> )  \___|    < | \_\ (  <_> > <  <
 *   Firmware   |____|_  /\____/ \___  >__|_ \|___  /\____/__/\_ \
 *                     \/            \/     \/    \/            \/
 * $Id$
 *
 * Copyright (C) 2002 by Ulf Ralberg
 *
 * This program is free software; you can redistribute it and/or
 * modify it under the terms of the GNU General Public License
 * as published by the Free Software Foundation; either version 2
 * of the License, or (at your option) any later version.
 *
 * This software is distributed on an "AS IS" basis, WITHOUT WARRANTY OF ANY
 * KIND, either express or implied.
 *
 ***************************************************************************
 * The sp check in glibc __longjmp_chk() will cause
 * a fatal error when switching threads via longjmp().
  Define THREAD_EXTRA_CHECKS as 1 to enable additional state checks  Always 1 for DEBUG ***************************************************************************
 *                              ATTENTION!!                                 *
 *    See notes below on implementing processor-specific portions!          *
 ****************************************************************************
 *
 * General locking order to guarantee progress. Order must be observed but
 * all stages are not nescessarily obligatory. Going from 1) to 3) is
 * perfectly legal.
 *
 * 1) IRQ
 * This is first because of the likelyhood of having an interrupt occur that
 * also accesses one of the objects farther down the list. Any non-blocking
 * synchronization done may already have a lock on something during normal
 * execution and if an interrupt handler running on the same processor as
 * the one that has the resource locked were to attempt to access the
 * resource, the interrupt handler would wait forever waiting for an unlock
 * that will never happen. There is no danger if the interrupt occurs on
 * a different processor because the one that has the lock will eventually
 * unlock and the other processor's handler may proceed at that time. Not
 * nescessary when the resource in question is definitely not available to
 * interrupt handlers.
 *
 * 2) Kernel Object
 * 1) May be needed beforehand if the kernel object allows dual-use such as
 * event queues. The kernel object must have a scheme to protect itself from
 * access by another processor and is responsible for serializing the calls
 * to block_thread  and wakeup_thread both to themselves and to each other.
 * Objects' queues are also protected here.
 *
 * 3) Thread Slot
 * This locks access to the thread's slot such that its state cannot be
 * altered by another processor when a state change is in progress such as
 * when it is in the process of going on a blocked list. An attempt to wake
 * a thread while it is still blocking will likely desync its state with
 * the other resources used for that state.
 *
 * 4) Core Lists
 * These lists are specific to a particular processor core and are accessible
 * by all processor cores and interrupt handlers. The running (rtr) list is
 * the prime example where a thread may be added by any means.
 ---------------------------------------------------------------------------
 * Processor specific: core_sleep/core_wake/misc. notes
 *
 * ARM notes:
 * FIQ is not dealt with by the scheduler code and is simply restored if it
 * must by masked for some reason - because threading modifies a register
 * that FIQ may also modify and there's no way to accomplish it atomically.
 * s3c2440 is such a case.
 *
 * Audio interrupts are generally treated at a higher priority than others
 * usage of scheduler code with interrupts higher than HIGHEST_IRQ_LEVEL
 * are not in general safe. Special cases may be constructed on a per-
 * source basis and blocking operations are not available.
 *
 * core_sleep procedure to implement for any CPU to ensure an asychronous
 * wakup never results in requiring a wait until the next tick (up to
 * 10000uS!). May require assembly and careful instruction ordering.
 *
 * 1) On multicore, stay awake if directed to do so by another. If so, goto
 *    step 4.
 * 2) If processor requires, atomically reenable interrupts and perform step
 *    3.
 * 3) Sleep the CPU core. If wakeup itself enables interrupts (stop #0x2000
 *    on Coldfire) goto step 5.
 * 4) Enable interrupts.
 * 5) Exit procedure.
 *
 * core_wake and multprocessor notes for sleep/wake coordination:
 * If possible, to wake up another processor, the forcing of an interrupt on
 * the woken core by the waker core is the easiest way to ensure a non-
 * delayed wake and immediate execution of any woken threads. If that isn't
 * available then some careful non-blocking synchonization is needed (as on
 * PP targets at the moment).
 *---------------------------------------------------------------------------
 *
 *
 *---------------------------------------------------------------------------
 * Priority distribution structure (one category for each possible priority):
 *
 *       +----+----+----+ ... +------+
 * hist: | F0 | F1 | F2 |     | Fn-1 |
 *       +----+----+----+ ... +------+
 * mask: | b0 | b1 | b2 |     | bn-1 |
 *       +----+----+----+ ... +------+
 *
 * F = count of threads at priority category n (frequency)
 * b = bitmask of non-zero priority categories (occupancy)
 *
 *        / if H[n] != 0 : 1
 * b[n] = |
 *        \ else         : 0
 *
 *---------------------------------------------------------------------------
 * Basic priority inheritance priotocol (PIP):
 *
 * Mn = mutex n, Tn = thread n
 *
 * A lower priority thread inherits the priority of the highest priority
 * thread blocked waiting for it to complete an action (such as release a
 * mutex or respond to a message via queue_send):
 *
 * 1) T2->M1->T1
 *
 * T1 owns M1, T2 is waiting for M1 to realease M1. If T2 has a higher
 * priority than T1 then T1 inherits the priority of T2.
 *
 * 2) T3
 *    \/
 *    T2->M1->T1
 *
 * Situation is like 1) but T2 and T3 are both queued waiting for M1 and so
 * T1 inherits the higher of T2 and T3.
 *
 * 3) T3->M2->T2->M1->T1
 *
 * T1 owns M1, T2 owns M2. If T3 has a higher priority than both T1 and T2,
 * then T1 inherits the priority of T3 through T2.
 *
 * Blocking chains can grow arbitrarily complex (though it's best that they
 * not form at all very often :) and build-up from these units.
 *---------------------------------------------------------------------------
 ***************************************************************************
 * Processor/OS-specific section - include necessary core support
  CPU_PP 
 * End Processor-specific section
 ************************************************************************** THREAD_EXTRA_CHECKS  Thread locking  NUM_CORES == 1 NUM_CORES  RTR list  !HAVE_PRIORITY_SCHEDULING  HAVE_PRIORITY_SCHEDULING  Forget about it if different CPU  Just woke something therefore a thread is on the run queue  There is a thread ready to run of higher priority on the same
     * core as the current one; recommend a task switch.  HAVE_PRIORITY_SCHEDULING ---------------------------------------------------------------------------
 * Increment frequency at category "priority"
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Decrement frequency at category "priority"
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Remove from one category and add to another
 *---------------------------------------------------------------------------
  HAVE_PRIORITY_SCHEDULING ---------------------------------------------------------------------------
 * Common init for new thread basic info
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Move a thread onto the core's run queue and promote it
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Remove a thread from the core's run queue
 *---------------------------------------------------------------------------
  Does not demote state ---------------------------------------------------------------------------
 * Move a thread back to a running state on its core
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Locks the thread registered as the owner of the block and makes sure it
 * didn't change in the meantime
 *---------------------------------------------------------------------------
  NUM_CORES > 1  The blocker thread may change during the process of trying to
       capture it  TRY, or else deadlocks are possible  Still multi  NUM_CORES  NUM_CORES > 1---------------------------------------------------------------------------
 * Change the priority and rtr entry for a running thread
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Finds the highest priority thread in a list of threads. If the list is
 * empty, the PRIORITY_IDLE is returned.
 *
 * It is possible to use the struct priority_distribution within an object
 * instead of scanning the remaining threads in the list but as a compromise,
 * the resulting per-object memory overhead is saved at a slight speed
 * penalty under high contention.
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Register priority with blocking system and bubble it down the chain if
 * any until we reach the end or something is already equal or higher.
 *
 * NOTE: A simultaneous circular wait could spin deadlock on multiprocessor
 * targets but that same action also guarantees a circular block anyway and
 * those are prevented, right? :-)
 *---------------------------------------------------------------------------
  Multiple owners  Recurse down the all the branches of this; it's the only way.
               We might meet the same queue several times if more than one of
               these threads is waiting the same queue. That isn't a problem
               for us since we early-terminate, just notable.  To see the change each time  Update blocker thread inheritance record  No blocker thread priority change  Running: last in chain  Blocker is blocked  Block doesn't support PIP  Full circle - deadlock!  Blocker becomes current thread and the process repeats  Adjust this wait queue  Queue priority not changing ---------------------------------------------------------------------------
 * Quick-inherit of priority elevation. 'thread' must be not runnable
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Quick-disinherit of priority elevation. 'thread' must current
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Transfer ownership from a single owner to a multi-owner splay from a wait
 * queue
 *---------------------------------------------------------------------------
  All threads will have the same blocker and queue; only we are changing
       it now  The first thread is already locked and is assumed tagged "multi"  Multiple versions of the wait queue may be seen if doing more than
       one thread; queue removal isn't destructive to the pointers of the node
       being removed; this may lead to the blocker priority being wrong for a
       time but it gets fixed up below after getting exclusive access to the
       queue  Locking order reverses here since the threads are no longer on the
       queued side  Becomes a simple, direct transfer ---------------------------------------------------------------------------
 * Transfer ownership to a thread waiting for an objects and transfer
 * inherited priority boost from other waiters. This algorithm knows that
 * blocking chains may only unblock from the very end.
 *
 * Only the owning thread itself may call this and so the assumption that
 * it is the running thread is made.
 *---------------------------------------------------------------------------
  Waking thread inherits priority boost from object owner (blt)  Remove the object's boost from the owning thread  Expected shortcut - no more waiters  If thread is at the blocker priority, its removal may drop it  This thread pwns  Save highest blocked priority ---------------------------------------------------------------------------
 * Readjust priorities when waking a thread blocked waiting for another
 * in essence "releasing" the thread's effect on the object owner. Can be
 * performed from any context.
 *---------------------------------------------------------------------------
  Off to see the wizard...  Queue priority won't change  Blocker priority won't change  HAVE_PRIORITY_SCHEDULING ---------------------------------------------------------------------------
 * Explicitly wakeup a thread on a blocking queue. Only effects threads of
 * STATE_BLOCKED and STATE_BLOCKED_W_TMO.
 *
 * INTERNAL: Intended for use by kernel and not programs.
 *---------------------------------------------------------------------------
  Determine thread's current state.  Threads with PIP blockers cannot specify "WAKEUP_DEFAULT"  Call the specified unblocking PIP (does the rest)  HAVE_PRIORITY_SCHEDULING  timed out ---------------------------------------------------------------------------
 * Check the core's timeout list when at least one thread is due to wake.
 * Filtering for the condition is done before making the call. Resets the
 * tick when the next check will occur.
 *---------------------------------------------------------------------------
  snapshot the current tick  minimum duration: once/minute  If there are no processes waiting for a timeout, just keep the check
       tick from falling into the past.  Break the loop once we have walked through the list of all
     * sleeping processes or have removed them all.  Check sleeping threads. Allow interrupts between checks.  Lock thread slot against explicit wakeup  Timeout still pending - this will be the usual case  Move the next check up to its time  TODO: there are no priority-inheriting timeout blocks
               right now but the procedure should be established  Sleep timeout has been reached / garbage collect stale list
               items  removed this one - prev doesn't change ---------------------------------------------------------------------------
 * Prepares a the current thread to sleep forever or for the given duration.
 *---------------------------------------------------------------------------
  Remove the thread from the list of running threads.  Sleep may expire.  Report new state. ---------------------------------------------------------------------------
 * Switch thread in round robin fashion for any given priority. Any thread
 * that removed itself from the running list first must specify itself in
 * the paramter.
 *
 * INTERNAL: Intended for use by kernel and not programs.
 *---------------------------------------------------------------------------
  Check core_ctx buflib integrity  Check if the current thread stack is overflown  TODO: make a real idle task  Check for expired timeouts  Enter sleep mode to reduce power usage  Awakened by interrupt or other CPU  Select the new task based on priorities and the last time a
     * process got CPU time relative to the highest priority runnable
     * task. If priority is not a feature, then FCFS is used (above).  This ridiculously simple method of aging seems to work
         * suspiciously well. It does tend to reward CPU hogs (under
         * yielding) but that's generally not desirable at all. On
         * the plus side, it, relatively to other threads, penalizes
         * excess yielding which is good if some high priority thread
         * is performing no useful work such as polling for a device
         * to be ready. Of course, aging is only employed when higher
         * and lower priority threads are runnable. The highest
         * priority runnable thread(s) are never skipped unless a
         * lower-priority process has aged sufficiently. Priorities
         * of REALTIME class are run strictly according to priority
         * thus are not subject to switchout due to lower-priority
         * processes aging; they must give up the processor by going
         * off the run list.  Reset aging counter  HAVE_PRIORITY_SCHEDULING  And finally, give control to the next thread. ---------------------------------------------------------------------------
 * Sleeps a thread for at least a specified number of ticks with zero being
 * a wait until the next tick.
 *
 * INTERNAL: Intended for use by kernel and not programs.
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Block a thread on a blocking queue for explicit wakeup. If timeout is
 * negative, the block is infinite.
 *
 * INTERNAL: Intended for use by kernel and not programs.
 *---------------------------------------------------------------------------
  HAVE_PRIORITY_SCHEDULING  Queue priority won't change  HAVE_PRIORITY_SCHEDULING ---------------------------------------------------------------------------
 * Place the current core in idle mode - woken up on interrupt or wake
 * request from another core.
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Create a thread. If using a dual core architecture, specify which core to
 * start the thread on.
 *
 * Return ID if context area could be allocated, else NULL.
 *---------------------------------------------------------------------------
  Munge the stack to make it easy to spot stack overflows  Writeback stack munging or anything else before starting  Snapshot while locked ---------------------------------------------------------------------------
 * Block the current thread until another thread terminates. A thread may
 * wait on itself to terminate but that will deadlock
 *.
 * Parameter is the ID as returned from create_thread().
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Exit the current thread
 *---------------------------------------------------------------------------
  Slot is no longer this thread  No longer using resources from creator  This should never and must never be reached - if it is, the
     * state is corrupted  Cancel CPU boost if any  Only one bit in the mask should be set with a frequency on 1 which
     * represents the thread's own base priority otherwise threads are waiting
     * on an abandoned object  HAVE_PRIORITY_SCHEDULING  Remove from scheduler lists  No switch_thread context save  Do final release of resources and remove the thread ---------------------------------------------------------------------------
 * Sets the thread's relative base priority for the core it runs on. Any
 * needed inheritance changes also may happen.
 *---------------------------------------------------------------------------
  Invalid priority argument  Invalid thread  No base priority change  Adjust the thread's priority influence on itself  No running priority change  This thread is running - just change location on the run queue.
           Also sets thread->priority.  Thread is blocked  End of transitive blocks ---------------------------------------------------------------------------
 * Returns the current base priority for a thread.
 *---------------------------------------------------------------------------
  Simply check without locking slot. It may or may not be valid by the
     * time the function returns anyway. If all tests pass, it is the
     * correct value for when it was valid.  HAVE_PRIORITY_SCHEDULING ---------------------------------------------------------------------------
 * Starts a frozen thread - similar semantics to wakeup_thread except that
 * the thread is on no scheduler or wakeup queue at all. It exists simply by
 * virtue of the slot having a state of STATE_FROZEN.
 *---------------------------------------------------------------------------
  If thread is the current one, it cannot be frozen, therefore
     * there is no need to check that. ---------------------------------------------------------------------------
 * Switch the processor that the currently executing thread runs on.
 *---------------------------------------------------------------------------
  Old core won't be using slot resources at this point  not reached  No change  Remove us from old core lists  No switch_thread context save  Do the actual migration  Executing on new core  NUM_CORES > 1 ---------------------------------------------------------------------------
 * Change the boost state of a thread boosting or unboosting the CPU
 * as required.
 *---------------------------------------------------------------------------
  HAVE_SCHEDULER_BOOSTCTRL ---------------------------------------------------------------------------
 * Initialize threading API. This assumes interrupts are not yet enabled. On
 * multicore setups, no core is allowed to proceed until create_thread calls
 * are safe to perform.
 *---------------------------------------------------------------------------
  before using cores!  Create main thread  WTF? There really must be a slot available at this stage.
             * This can fail if, for example, .bss isn't zero'ed out by the
             * loader or threads is in the wrong section.  Boot CPU:
     * Wait for other processors to finish their inits since create_thread
     * isn't safe to call until the kernel inits are done. The first
     * threads created in the system must of course be created by CPU.
     * Another possible approach is to initialize all cores and slots
     * for each core by CPU, let the remainder proceed in parallel and
     * signal CPU when all are finished.
     *
     * Other:
     * After last processor completes, it should signal all others to
     * proceed or may signal the next and call thread_exit(). The last one
     * to finish will signal CPU.
      No main thread on coprocessors - go idle and wait  NUM_CORES **************************************************************************
 *             __________               __   ___.
 *   Open      \______   \ ____   ____ |  | _\_ |__   _______  ___
 *   Source     |       _//  _ \_/ ___\|  |/ /| __ \ /  _ \  \/  /
 *   Jukebox    |    |   (  <_> )  \___|    < | \_\ (  <_> > <  <
 *   Firmware   |____|_  /\____/ \___  >__|_ \|___  /\____/__/\_ \
 *                     \/            \/     \/    \/            \/
 * $Id$
 *
 * Copyright (C) 2002 by Ulf Ralberg
 *
 * This program is free software; you can redistribute it and/or
 * modify it under the terms of the GNU General Public License
 * as published by the Free Software Foundation; either version 2
 * of the License, or (at your option) any later version.
 *
 * This software is distributed on an "AS IS" basis, WITHOUT WARRANTY OF ANY
 * KIND, either express or implied.
 *
 ***************************************************************************
 * The sp check in glibc __longjmp_chk() will cause
 * a fatal error when switching threads via longjmp().
  Define THREAD_EXTRA_CHECKS as 1 to enable additional state checks  Always 1 for DEBUG ***************************************************************************
 *                              ATTENTION!!                                 *
 *    See notes below on implementing processor-specific portions!          *
 ****************************************************************************
 *
 * General locking order to guarantee progress. Order must be observed but
 * all stages are not nescessarily obligatory. Going from 1) to 3) is
 * perfectly legal.
 *
 * 1) IRQ
 * This is first because of the likelyhood of having an interrupt occur that
 * also accesses one of the objects farther down the list. Any non-blocking
 * synchronization done may already have a lock on something during normal
 * execution and if an interrupt handler running on the same processor as
 * the one that has the resource locked were to attempt to access the
 * resource, the interrupt handler would wait forever waiting for an unlock
 * that will never happen. There is no danger if the interrupt occurs on
 * a different processor because the one that has the lock will eventually
 * unlock and the other processor's handler may proceed at that time. Not
 * nescessary when the resource in question is definitely not available to
 * interrupt handlers.
 *
 * 2) Kernel Object
 * 1) May be needed beforehand if the kernel object allows dual-use such as
 * event queues. The kernel object must have a scheme to protect itself from
 * access by another processor and is responsible for serializing the calls
 * to block_thread  and wakeup_thread both to themselves and to each other.
 * Objects' queues are also protected here.
 *
 * 3) Thread Slot
 * This locks access to the thread's slot such that its state cannot be
 * altered by another processor when a state change is in progress such as
 * when it is in the process of going on a blocked list. An attempt to wake
 * a thread while it is still blocking will likely desync its state with
 * the other resources used for that state.
 *
 * 4) Core Lists
 * These lists are specific to a particular processor core and are accessible
 * by all processor cores and interrupt handlers. The running (rtr) list is
 * the prime example where a thread may be added by any means.
 ---------------------------------------------------------------------------
 * Processor specific: core_sleep/core_wake/misc. notes
 *
 * ARM notes:
 * FIQ is not dealt with by the scheduler code and is simply restored if it
 * must by masked for some reason - because threading modifies a register
 * that FIQ may also modify and there's no way to accomplish it atomically.
 * s3c2440 is such a case.
 *
 * Audio interrupts are generally treated at a higher priority than others
 * usage of scheduler code with interrupts higher than HIGHEST_IRQ_LEVEL
 * are not in general safe. Special cases may be constructed on a per-
 * source basis and blocking operations are not available.
 *
 * core_sleep procedure to implement for any CPU to ensure an asychronous
 * wakup never results in requiring a wait until the next tick (up to
 * 10000uS!). May require assembly and careful instruction ordering.
 *
 * 1) On multicore, stay awake if directed to do so by another. If so, goto
 *    step 4.
 * 2) If processor requires, atomically reenable interrupts and perform step
 *    3.
 * 3) Sleep the CPU core. If wakeup itself enables interrupts (stop #0x2000
 *    on Coldfire) goto step 5.
 * 4) Enable interrupts.
 * 5) Exit procedure.
 *
 * core_wake and multprocessor notes for sleep/wake coordination:
 * If possible, to wake up another processor, the forcing of an interrupt on
 * the woken core by the waker core is the easiest way to ensure a non-
 * delayed wake and immediate execution of any woken threads. If that isn't
 * available then some careful non-blocking synchonization is needed (as on
 * PP targets at the moment).
 *---------------------------------------------------------------------------
 *
 *
 *---------------------------------------------------------------------------
 * Priority distribution structure (one category for each possible priority):
 *
 *       +----+----+----+ ... +------+
 * hist: | F0 | F1 | F2 |     | Fn-1 |
 *       +----+----+----+ ... +------+
 * mask: | b0 | b1 | b2 |     | bn-1 |
 *       +----+----+----+ ... +------+
 *
 * F = count of threads at priority category n (frequency)
 * b = bitmask of non-zero priority categories (occupancy)
 *
 *        / if H[n] != 0 : 1
 * b[n] = |
 *        \ else         : 0
 *
 *---------------------------------------------------------------------------
 * Basic priority inheritance priotocol (PIP):
 *
 * Mn = mutex n, Tn = thread n
 *
 * A lower priority thread inherits the priority of the highest priority
 * thread blocked waiting for it to complete an action (such as release a
 * mutex or respond to a message via queue_send):
 *
 * 1) T2->M1->T1
 *
 * T1 owns M1, T2 is waiting for M1 to realease M1. If T2 has a higher
 * priority than T1 then T1 inherits the priority of T2.
 *
 * 2) T3
 *    \/
 *    T2->M1->T1
 *
 * Situation is like 1) but T2 and T3 are both queued waiting for M1 and so
 * T1 inherits the higher of T2 and T3.
 *
 * 3) T3->M2->T2->M1->T1
 *
 * T1 owns M1, T2 owns M2. If T3 has a higher priority than both T1 and T2,
 * then T1 inherits the priority of T3 through T2.
 *
 * Blocking chains can grow arbitrarily complex (though it's best that they
 * not form at all very often :) and build-up from these units.
 *---------------------------------------------------------------------------
 ***************************************************************************
 * Processor/OS-specific section - include necessary core support
  CPU_PP 
 * End Processor-specific section
 ************************************************************************** THREAD_EXTRA_CHECKS  Thread locking  NUM_CORES == 1 NUM_CORES  RTR list  !HAVE_PRIORITY_SCHEDULING  HAVE_PRIORITY_SCHEDULING  Forget about it if different CPU  Just woke something therefore a thread is on the run queue  There is a thread ready to run of higher priority on the same
     * core as the current one; recommend a task switch.  HAVE_PRIORITY_SCHEDULING ---------------------------------------------------------------------------
 * Increment frequency at category "priority"
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Decrement frequency at category "priority"
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Remove from one category and add to another
 *---------------------------------------------------------------------------
  HAVE_PRIORITY_SCHEDULING ---------------------------------------------------------------------------
 * Common init for new thread basic info
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Move a thread onto the core's run queue and promote it
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Remove a thread from the core's run queue
 *---------------------------------------------------------------------------
  Does not demote state ---------------------------------------------------------------------------
 * Move a thread back to a running state on its core
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Locks the thread registered as the owner of the block and makes sure it
 * didn't change in the meantime
 *---------------------------------------------------------------------------
  NUM_CORES > 1  The blocker thread may change during the process of trying to
       capture it  TRY, or else deadlocks are possible  Still multi  NUM_CORES  NUM_CORES > 1---------------------------------------------------------------------------
 * Change the priority and rtr entry for a running thread
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Finds the highest priority thread in a list of threads. If the list is
 * empty, the PRIORITY_IDLE is returned.
 *
 * It is possible to use the struct priority_distribution within an object
 * instead of scanning the remaining threads in the list but as a compromise,
 * the resulting per-object memory overhead is saved at a slight speed
 * penalty under high contention.
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Register priority with blocking system and bubble it down the chain if
 * any until we reach the end or something is already equal or higher.
 *
 * NOTE: A simultaneous circular wait could spin deadlock on multiprocessor
 * targets but that same action also guarantees a circular block anyway and
 * those are prevented, right? :-)
 *---------------------------------------------------------------------------
  Multiple owners  Recurse down the all the branches of this; it's the only way.
               We might meet the same queue several times if more than one of
               these threads is waiting the same queue. That isn't a problem
               for us since we early-terminate, just notable.  To see the change each time  Update blocker thread inheritance record  No blocker thread priority change  Running: last in chain  Blocker is blocked  Block doesn't support PIP  Full circle - deadlock!  Blocker becomes current thread and the process repeats  Adjust this wait queue  Queue priority not changing ---------------------------------------------------------------------------
 * Quick-inherit of priority elevation. 'thread' must be not runnable
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Quick-disinherit of priority elevation. 'thread' must current
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Transfer ownership from a single owner to a multi-owner splay from a wait
 * queue
 *---------------------------------------------------------------------------
  All threads will have the same blocker and queue; only we are changing
       it now  The first thread is already locked and is assumed tagged "multi"  Multiple versions of the wait queue may be seen if doing more than
       one thread; queue removal isn't destructive to the pointers of the node
       being removed; this may lead to the blocker priority being wrong for a
       time but it gets fixed up below after getting exclusive access to the
       queue  Locking order reverses here since the threads are no longer on the
       queued side  Becomes a simple, direct transfer ---------------------------------------------------------------------------
 * Transfer ownership to a thread waiting for an objects and transfer
 * inherited priority boost from other waiters. This algorithm knows that
 * blocking chains may only unblock from the very end.
 *
 * Only the owning thread itself may call this and so the assumption that
 * it is the running thread is made.
 *---------------------------------------------------------------------------
  Waking thread inherits priority boost from object owner (blt)  Remove the object's boost from the owning thread  Expected shortcut - no more waiters  If thread is at the blocker priority, its removal may drop it  This thread pwns  Save highest blocked priority ---------------------------------------------------------------------------
 * Readjust priorities when waking a thread blocked waiting for another
 * in essence "releasing" the thread's effect on the object owner. Can be
 * performed from any context.
 *---------------------------------------------------------------------------
  Off to see the wizard...  Queue priority won't change  Blocker priority won't change  HAVE_PRIORITY_SCHEDULING ---------------------------------------------------------------------------
 * Explicitly wakeup a thread on a blocking queue. Only effects threads of
 * STATE_BLOCKED and STATE_BLOCKED_W_TMO.
 *
 * INTERNAL: Intended for use by kernel and not programs.
 *---------------------------------------------------------------------------
  Determine thread's current state.  Threads with PIP blockers cannot specify "WAKEUP_DEFAULT"  Call the specified unblocking PIP (does the rest)  HAVE_PRIORITY_SCHEDULING  timed out ---------------------------------------------------------------------------
 * Check the core's timeout list when at least one thread is due to wake.
 * Filtering for the condition is done before making the call. Resets the
 * tick when the next check will occur.
 *---------------------------------------------------------------------------
  snapshot the current tick  minimum duration: once/minute  If there are no processes waiting for a timeout, just keep the check
       tick from falling into the past.  Break the loop once we have walked through the list of all
     * sleeping processes or have removed them all.  Check sleeping threads. Allow interrupts between checks.  Lock thread slot against explicit wakeup  Timeout still pending - this will be the usual case  Move the next check up to its time  TODO: there are no priority-inheriting timeout blocks
               right now but the procedure should be established  Sleep timeout has been reached / garbage collect stale list
               items  removed this one - prev doesn't change ---------------------------------------------------------------------------
 * Prepares a the current thread to sleep forever or for the given duration.
 *---------------------------------------------------------------------------
  Remove the thread from the list of running threads.  Sleep may expire.  Report new state. ---------------------------------------------------------------------------
 * Switch thread in round robin fashion for any given priority. Any thread
 * that removed itself from the running list first must specify itself in
 * the paramter.
 *
 * INTERNAL: Intended for use by kernel and not programs.
 *---------------------------------------------------------------------------
  Check core_ctx buflib integrity  Check if the current thread stack is overflown  TODO: make a real idle task  Check for expired timeouts  Enter sleep mode to reduce power usage  Awakened by interrupt or other CPU  Select the new task based on priorities and the last time a
     * process got CPU time relative to the highest priority runnable
     * task. If priority is not a feature, then FCFS is used (above).  This ridiculously simple method of aging seems to work
         * suspiciously well. It does tend to reward CPU hogs (under
         * yielding) but that's generally not desirable at all. On
         * the plus side, it, relatively to other threads, penalizes
         * excess yielding which is good if some high priority thread
         * is performing no useful work such as polling for a device
         * to be ready. Of course, aging is only employed when higher
         * and lower priority threads are runnable. The highest
         * priority runnable thread(s) are never skipped unless a
         * lower-priority process has aged sufficiently. Priorities
         * of REALTIME class are run strictly according to priority
         * thus are not subject to switchout due to lower-priority
         * processes aging; they must give up the processor by going
         * off the run list.  Reset aging counter  HAVE_PRIORITY_SCHEDULING  And finally, give control to the next thread. ---------------------------------------------------------------------------
 * Sleeps a thread for at least a specified number of ticks with zero being
 * a wait until the next tick.
 *
 * INTERNAL: Intended for use by kernel and not programs.
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Block a thread on a blocking queue for explicit wakeup. If timeout is
 * negative, the block is infinite.
 *
 * INTERNAL: Intended for use by kernel and not programs.
 *---------------------------------------------------------------------------
  HAVE_PRIORITY_SCHEDULING  Queue priority won't change  HAVE_PRIORITY_SCHEDULING ---------------------------------------------------------------------------
 * Place the current core in idle mode - woken up on interrupt or wake
 * request from another core.
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Create a thread. If using a dual core architecture, specify which core to
 * start the thread on.
 *
 * Return ID if context area could be allocated, else NULL.
 *---------------------------------------------------------------------------
  Munge the stack to make it easy to spot stack overflows  Writeback stack munging or anything else before starting  Snapshot while locked ---------------------------------------------------------------------------
 * Block the current thread until another thread terminates. A thread may
 * wait on itself to terminate but that will deadlock
 *.
 * Parameter is the ID as returned from create_thread().
 *---------------------------------------------------------------------------
 ---------------------------------------------------------------------------
 * Exit the current thread
 *---------------------------------------------------------------------------
  Slot is no longer this thread  No longer using resources from creator  This should never and must never be reached - if it is, the
     * state is corrupted  Cancel CPU boost if any  Only one bit in the mask should be set with a frequency on 1 which
     * represents the thread's own base priority otherwise threads are waiting
     * on an abandoned object  HAVE_PRIORITY_SCHEDULING  Remove from scheduler lists  No switch_thread context save  Do final release of resources and remove the thread ---------------------------------------------------------------------------
 * Sets the thread's relative base priority for the core it runs on. Any
 * needed inheritance changes also may happen.
 *---------------------------------------------------------------------------
  Invalid priority argument  Invalid thread  No base priority change  Adjust the thread's priority influence on itself  No running priority change  This thread is running - just change location on the run queue.
           Also sets thread->priority.  Thread is blocked  End of transitive blocks ---------------------------------------------------------------------------
 * Returns the current base priority for a thread.
 *---------------------------------------------------------------------------
  Simply check without locking slot. It may or may not be valid by the
     * time the function returns anyway. If all tests pass, it is the
     * correct value for when it was valid.  HAVE_PRIORITY_SCHEDULING ---------------------------------------------------------------------------
 * Starts a frozen thread - similar semantics to wakeup_thread except that
 * the thread is on no scheduler or wakeup queue at all. It exists simply by
 * virtue of the slot having a state of STATE_FROZEN.
 *---------------------------------------------------------------------------
  If thread is the current one, it cannot be frozen, therefore
     * there is no need to check that. ---------------------------------------------------------------------------
 * Switch the processor that the currently executing thread runs on.
 *---------------------------------------------------------------------------
  Old core won't be using slot resources at this point  not reached  No change  Remove us from old core lists  No switch_thread context save  Do the actual migration  Executing on new core  NUM_CORES > 1 ---------------------------------------------------------------------------
 * Change the boost state of a thread boosting or unboosting the CPU
 * as required.
 *---------------------------------------------------------------------------
  HAVE_SCHEDULER_BOOSTCTRL ---------------------------------------------------------------------------
 * Initialize threading API. This assumes interrupts are not yet enabled. On
 * multicore setups, no core is allowed to proceed until create_thread calls
 * are safe to perform.
 *---------------------------------------------------------------------------
  before using cores!  Create main thread  WTF? There really must be a slot available at this stage.
             * This can fail if, for example, .bss isn't zero'ed out by the
             * loader or threads is in the wrong section.  Boot CPU:
     * Wait for other processors to finish their inits since create_thread
     * isn't safe to call until the kernel inits are done. The first
     * threads created in the system must of course be created by CPU.
     * Another possible approach is to initialize all cores and slots
     * for each core by CPU, let the remainder proceed in parallel and
     * signal CPU when all are finished.
     *
     * Other:
     * After last processor completes, it should signal all others to
     * proceed or may signal the next and call thread_exit(). The last one
     * to finish will signal CPU.
      No main thread on coprocessors - go idle and wait  NUM_CORES 