*******************************************************************
 *                                                                  *
 * THIS FILE IS PART OF THE OggVorbis 'TREMOR' CODEC SOURCE CODE.   *
 *                                                                  *
 * USE, DISTRIBUTION AND REPRODUCTION OF THIS LIBRARY SOURCE IS     *
 * GOVERNED BY A BSD-STYLE SOURCE LICENSE INCLUDED WITH THIS SOURCE *
 * IN 'COPYING'. PLEASE READ THESE TERMS BEFORE DISTRIBUTING.       *
 *                                                                  *
 * THE OggVorbis 'TREMOR' SOURCE CODE IS (C) COPYRIGHT 1994-2002    *
 * BY THE Xiph.Org FOUNDATION http://www.xiph.org/                  *
 *                                                                  *
 ********************************************************************

 function: basic shared codebook operations

 ********************************************************************** pack/unpack helpers ***************************************** 32 bit float (not IEEE; nonnormalized mantissa +
   biased exponent) : neeeeeee eeemmmmm mmmmmmmm mmmmmmmm 
   Why not IEEE?  It's just not that important here.  bias toward values smaller than 1.  given a list of word lengths, generate a list of codewords.  Works
   for length ordered or unordered, always assigns the lowest valued
   codewords first.  Extended to handle unused entries (length 0)  when we claim a node for an entry, we also claim the nodes
         below it (pruning off the imagined tree that may have dangled
         from it) as well as blocking the use of any nodes directly
         above for leaves  update ourself  error condition; the lengths must specify an overpopulated tree  Look to see if the next shorter marker points to the node
         above. if so, update it and repeat.   have to jump branches  invariant says next upper marker would already
                      have been moved if it was on the same path  prune the tree; the implicit invariant says all the longer
         markers were dangling from our just-taken node.  Dangle them
         from our *new* node.  sanity check the huffman tree; an underpopulated tree must be
     rejected. The only exception is the one-node pseudo-nil tree,
     which appears to be underpopulated because the tree doesn't
     really exist; there's only one possible 'codeword' or zero bits,
     but the above tree-gen code doesn't mark that.  bitreverse the words because our bitwise packer/unpacker is LSb
     endian  there might be a straightforward one-line way to do the below
   that's portable and totally safe against roundoff, but I haven't
   thought of it.  Therefore, we opt on the side of caution  get us a starting hint, we'll polish it below  different than what _book_unquantize does for mainline:
   we repack the book in a fixed point format that shares the same
   binary point.  Upon first use, we can shift point if needed  we need to deal with two map types: in map type 1, the values are
   generated algorithmically (each column of the vector counts through
   the values in the quant vector). in map type 2, all the values came
   in in an explicit list.  Both value lists must be unpacked  maptype 1 and 2 both use a quantized value vector, but
       different sizes  most of the time, entries%dimensions == 0, but we need to be
         well defined.  We define that the possible vales at each
         scalar is values == entries/dim.  If entries%dim != 0, we'll
         have 'too few' values (values*dim<entries), which means that
         we'll have 'left over' entries; left over entries use zeroed
         values (and are wasted).  So don't generate codebooks like
         that  static book is not cleared; we're likely called on the lookup and
     the static codebook belongs to the info struct  decode codebook arrangement is more heavily optimized than encode  count actually used entries  two different remappings go on here.  
       
       First, we collapse the likely sparse codebook down only to
       actually represented values/words.  This collapsing needs to be
       indexed as map-valueless books are used to encode original entry
       positions as integers.
       
       Second, we reorder all vectors, including the entry index above,
       by sorted bitreversed codeword to allow treeless decode.  perform sort  the index is a reverse index  Use a larger cache size when we have a large codec buffer, helps decoding
   speed especially on targets with slow memory and high bitrate files  this is magic  this is magic  now fill in 'unused' entries in the firsttable with hi/lo search
       hints for the non-direct-hits  we only actually have 15 bits per hint to play with here.
             In order to overflow gracefully (nothing breaks, efficiency
             just drops), encode as the difference from the extremes. *******************************************************************
 *                                                                  *
 * THIS FILE IS PART OF THE OggVorbis 'TREMOR' CODEC SOURCE CODE.   *
 *                                                                  *
 * USE, DISTRIBUTION AND REPRODUCTION OF THIS LIBRARY SOURCE IS     *
 * GOVERNED BY A BSD-STYLE SOURCE LICENSE INCLUDED WITH THIS SOURCE *
 * IN 'COPYING'. PLEASE READ THESE TERMS BEFORE DISTRIBUTING.       *
 *                                                                  *
 * THE OggVorbis 'TREMOR' SOURCE CODE IS (C) COPYRIGHT 1994-2002    *
 * BY THE Xiph.Org FOUNDATION http://www.xiph.org/                  *
 *                                                                  *
 ********************************************************************

 function: basic shared codebook operations

 ********************************************************************** pack/unpack helpers ***************************************** 32 bit float (not IEEE; nonnormalized mantissa +
   biased exponent) : neeeeeee eeemmmmm mmmmmmmm mmmmmmmm 
   Why not IEEE?  It's just not that important here.  bias toward values smaller than 1.  given a list of word lengths, generate a list of codewords.  Works
   for length ordered or unordered, always assigns the lowest valued
   codewords first.  Extended to handle unused entries (length 0)  when we claim a node for an entry, we also claim the nodes
         below it (pruning off the imagined tree that may have dangled
         from it) as well as blocking the use of any nodes directly
         above for leaves  update ourself  error condition; the lengths must specify an overpopulated tree  Look to see if the next shorter marker points to the node
         above. if so, update it and repeat.   have to jump branches  invariant says next upper marker would already
                      have been moved if it was on the same path  prune the tree; the implicit invariant says all the longer
         markers were dangling from our just-taken node.  Dangle them
         from our *new* node.  sanity check the huffman tree; an underpopulated tree must be
     rejected. The only exception is the one-node pseudo-nil tree,
     which appears to be underpopulated because the tree doesn't
     really exist; there's only one possible 'codeword' or zero bits,
     but the above tree-gen code doesn't mark that.  bitreverse the words because our bitwise packer/unpacker is LSb
     endian  there might be a straightforward one-line way to do the below
   that's portable and totally safe against roundoff, but I haven't
   thought of it.  Therefore, we opt on the side of caution  get us a starting hint, we'll polish it below  different than what _book_unquantize does for mainline:
   we repack the book in a fixed point format that shares the same
   binary point.  Upon first use, we can shift point if needed  we need to deal with two map types: in map type 1, the values are
   generated algorithmically (each column of the vector counts through
   the values in the quant vector). in map type 2, all the values came
   in in an explicit list.  Both value lists must be unpacked  maptype 1 and 2 both use a quantized value vector, but
       different sizes  most of the time, entries%dimensions == 0, but we need to be
         well defined.  We define that the possible vales at each
         scalar is values == entries/dim.  If entries%dim != 0, we'll
         have 'too few' values (values*dim<entries), which means that
         we'll have 'left over' entries; left over entries use zeroed
         values (and are wasted).  So don't generate codebooks like
         that  static book is not cleared; we're likely called on the lookup and
     the static codebook belongs to the info struct  decode codebook arrangement is more heavily optimized than encode  count actually used entries  two different remappings go on here.  
       
       First, we collapse the likely sparse codebook down only to
       actually represented values/words.  This collapsing needs to be
       indexed as map-valueless books are used to encode original entry
       positions as integers.
       
       Second, we reorder all vectors, including the entry index above,
       by sorted bitreversed codeword to allow treeless decode.  perform sort  the index is a reverse index  Use a larger cache size when we have a large codec buffer, helps decoding
   speed especially on targets with slow memory and high bitrate files  this is magic  this is magic  now fill in 'unused' entries in the firsttable with hi/lo search
       hints for the non-direct-hits  we only actually have 15 bits per hint to play with here.
             In order to overflow gracefully (nothing breaks, efficiency
             just drops), encode as the difference from the extremes. *******************************************************************
 *                                                                  *
 * THIS FILE IS PART OF THE OggVorbis 'TREMOR' CODEC SOURCE CODE.   *
 *                                                                  *
 * USE, DISTRIBUTION AND REPRODUCTION OF THIS LIBRARY SOURCE IS     *
 * GOVERNED BY A BSD-STYLE SOURCE LICENSE INCLUDED WITH THIS SOURCE *
 * IN 'COPYING'. PLEASE READ THESE TERMS BEFORE DISTRIBUTING.       *
 *                                                                  *
 * THE OggVorbis 'TREMOR' SOURCE CODE IS (C) COPYRIGHT 1994-2002    *
 * BY THE Xiph.Org FOUNDATION http://www.xiph.org/                  *
 *                                                                  *
 ********************************************************************

 function: basic shared codebook operations

 ********************************************************************** pack/unpack helpers ***************************************** 32 bit float (not IEEE; nonnormalized mantissa +
   biased exponent) : neeeeeee eeemmmmm mmmmmmmm mmmmmmmm 
   Why not IEEE?  It's just not that important here.  bias toward values smaller than 1.  given a list of word lengths, generate a list of codewords.  Works
   for length ordered or unordered, always assigns the lowest valued
   codewords first.  Extended to handle unused entries (length 0)  when we claim a node for an entry, we also claim the nodes
         below it (pruning off the imagined tree that may have dangled
         from it) as well as blocking the use of any nodes directly
         above for leaves  update ourself  error condition; the lengths must specify an overpopulated tree  Look to see if the next shorter marker points to the node
         above. if so, update it and repeat.   have to jump branches  invariant says next upper marker would already
                      have been moved if it was on the same path  prune the tree; the implicit invariant says all the longer
         markers were dangling from our just-taken node.  Dangle them
         from our *new* node.  sanity check the huffman tree; an underpopulated tree must be
     rejected. The only exception is the one-node pseudo-nil tree,
     which appears to be underpopulated because the tree doesn't
     really exist; there's only one possible 'codeword' or zero bits,
     but the above tree-gen code doesn't mark that.  bitreverse the words because our bitwise packer/unpacker is LSb
     endian  there might be a straightforward one-line way to do the below
   that's portable and totally safe against roundoff, but I haven't
   thought of it.  Therefore, we opt on the side of caution  get us a starting hint, we'll polish it below  different than what _book_unquantize does for mainline:
   we repack the book in a fixed point format that shares the same
   binary point.  Upon first use, we can shift point if needed  we need to deal with two map types: in map type 1, the values are
   generated algorithmically (each column of the vector counts through
   the values in the quant vector). in map type 2, all the values came
   in in an explicit list.  Both value lists must be unpacked  maptype 1 and 2 both use a quantized value vector, but
       different sizes  most of the time, entries%dimensions == 0, but we need to be
         well defined.  We define that the possible vales at each
         scalar is values == entries/dim.  If entries%dim != 0, we'll
         have 'too few' values (values*dim<entries), which means that
         we'll have 'left over' entries; left over entries use zeroed
         values (and are wasted).  So don't generate codebooks like
         that  static book is not cleared; we're likely called on the lookup and
     the static codebook belongs to the info struct  decode codebook arrangement is more heavily optimized than encode  count actually used entries  two different remappings go on here.  
       
       First, we collapse the likely sparse codebook down only to
       actually represented values/words.  This collapsing needs to be
       indexed as map-valueless books are used to encode original entry
       positions as integers.
       
       Second, we reorder all vectors, including the entry index above,
       by sorted bitreversed codeword to allow treeless decode.  perform sort  the index is a reverse index  Use a larger cache size when we have a large codec buffer, helps decoding
   speed especially on targets with slow memory and high bitrate files  this is magic  this is magic  now fill in 'unused' entries in the firsttable with hi/lo search
       hints for the non-direct-hits  we only actually have 15 bits per hint to play with here.
             In order to overflow gracefully (nothing breaks, efficiency
             just drops), encode as the difference from the extremes. 